{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# neural network with 5 layers\n",
    "\n",
    "· · · · · · · · · ·          (input data, flattened pixels)       X [batch, 784]   # 784 = 28*28\n",
    "\\x/x\\x/x\\x/x\\x/x\\x/      -- fully connected layer (relu+dropout) W1 [784, 200]      B1[200]\n",
    " · · · · · · · · ·                                                Y1 [batch, 200]\n",
    "  \\x/x\\x/x\\x/x\\x/        -- fully connected layer (relu+dropout) W2 [200, 100]      B2[100]\n",
    "   · · · · · · ·                                                  Y2 [batch, 100]\n",
    "    \\x/x\\x/x\\x/          -- fully connected layer (relu+dropout) W3 [100, 60]       B3[60]\n",
    "     · · · · ·                                                    Y3 [batch, 60]\n",
    "      \\x/x\\x/            -- fully connected layer (relu+dropout) W4 [60, 30]        B4[30]\n",
    "       · · ·                                                      Y4 [batch, 30]\n",
    "        \\x/               -- fully connected layer (softmax)      W5 [30, 10]        B5[10]\n",
    "         ·                                                        Y5 [batch, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0d84f1be5514>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOGDIR = 'mnist_tutorial/'\n",
    "mnist = mnist_data.read_data_sets(train_dir=LOGDIR + \"data\", one_hot=True, reshape=False, validation_size=0)\n",
    "\n",
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1], name='X')\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10], name='lable')\n",
    "\n",
    "x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "tf.summary.image('input', x_image, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images into a single line of pixels\n",
    "# -1 in the shape definition means \"the only possible dimension that will preserve the number of elements\"\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "# Probability of keeping a node during dropout = 1.0 at test time (no dropout) and 0.75 at training time\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five layers and their number of neurons (tha last layer has 10 softmax neurons)\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initialised with small random values between -0.2 and +0.2\n",
    "# When using RELUs, make sure biases are initialised with small *positive* values for example 0.1 = tf.ones([K])/10\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\", act=tf.nn.relu):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    preact = tf.matmul(input, w) + b\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(name + '/pre_activations', preact)\n",
    "    if act==tf.nn.softmax:\n",
    "        return preact\n",
    "    activations = act(preact, 'activation')\n",
    "    tf.summary.histogram(name + '/activations', activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model, with dropout at each layer\n",
    "\n",
    "FC1 = fc_layer(XX, 28*28, L, \"FC1\")\n",
    "FC1D = tf.nn.dropout(FC1, pkeep)\n",
    "FC2 = fc_layer(FC1D, L, M, \"FC2\")\n",
    "FC2D = tf.nn.dropout(FC2, pkeep)\n",
    "FC3 = fc_layer(FC2D, M, N, \"FC3\")\n",
    "FC3D = tf.nn.dropout(FC3, pkeep)\n",
    "FC4 = fc_layer(FC3, N, O, \"FC4\")\n",
    "FC4D = tf.nn.dropout(FC4, pkeep)\n",
    "Ylogits = fc_layer(FC4D, O, 10, \"FC5\", act=tf.nn.softmax)\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5886126faa98>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "    tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "# summary merge\n",
    "summ = tf.summary.merge_all()\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(LOGDIR + str(2.2))\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(i, update_test_data, update_train_data):\n",
    "\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "\n",
    "    # learning rate decay\n",
    "    max_learning_rate = 0.003\n",
    "    min_learning_rate = 0.0001\n",
    "    decay_speed = 2000.0 # 0.003-0.0001-2000=>0.9826 done in 5000 iterations\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-i/decay_speed)\n",
    "\n",
    "    # compute training values for visualisation\n",
    "    if update_train_data:\n",
    "        a, c, s = sess.run([accuracy, cross_entropy, summ], {X: batch_X, Y_: batch_Y, pkeep: 1.0})\n",
    "        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c) + \" (lr:\" + str(learning_rate) + \")\")\n",
    "        writer.add_summary(s, i)\n",
    "    # compute test values for visualisation\n",
    "    if update_test_data:\n",
    "        a, c, s = sess.run([accuracy, cross_entropy, summ], {X: mnist.test.images, Y_: mnist.test.labels, pkeep: 1.0})\n",
    "        print(str(i) + \": ********* epoch \" + str(i*100//mnist.train.images.shape[0]+1) + \" ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "        writer.add_summary(s, i)\n",
    "    sess.run(train_step, {X: batch_X, Y_: batch_Y, pkeep: 0.75, lr: learning_rate})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: accuracy:0.16 loss: 229.68661 (lr:0.003)\n",
      "0: ********* epoch 1 ********* test accuracy:0.1299 test loss: 230.15019\n",
      "10: ********* epoch 1 ********* test accuracy:0.4801 test loss: 173.93202\n",
      "20: ********* epoch 1 ********* test accuracy:0.7112 test loss: 94.97679\n",
      "30: ********* epoch 1 ********* test accuracy:0.7629 test loss: 75.27462\n",
      "40: ********* epoch 1 ********* test accuracy:0.8459 test loss: 56.38913\n",
      "50: ********* epoch 1 ********* test accuracy:0.8638 test loss: 45.04578\n",
      "60: ********* epoch 1 ********* test accuracy:0.8682 test loss: 43.445377\n",
      "70: ********* epoch 1 ********* test accuracy:0.873 test loss: 42.76175\n",
      "80: ********* epoch 1 ********* test accuracy:0.8931 test loss: 37.316513\n",
      "90: ********* epoch 1 ********* test accuracy:0.8945 test loss: 36.255733\n",
      "100: accuracy:0.94 loss: 17.582012 (lr:0.0028585653310520707)\n",
      "100: ********* epoch 1 ********* test accuracy:0.9053 test loss: 31.13086\n",
      "110: ********* epoch 1 ********* test accuracy:0.9079 test loss: 30.58337\n",
      "120: ********* epoch 1 ********* test accuracy:0.9081 test loss: 30.77089\n",
      "130: ********* epoch 1 ********* test accuracy:0.9129 test loss: 28.596619\n",
      "140: ********* epoch 1 ********* test accuracy:0.9192 test loss: 27.014307\n",
      "150: ********* epoch 1 ********* test accuracy:0.9214 test loss: 26.36574\n",
      "160: ********* epoch 1 ********* test accuracy:0.9274 test loss: 24.363344\n",
      "170: ********* epoch 1 ********* test accuracy:0.9241 test loss: 25.1481\n",
      "180: ********* epoch 1 ********* test accuracy:0.9236 test loss: 26.159138\n",
      "190: ********* epoch 1 ********* test accuracy:0.9214 test loss: 26.524597\n",
      "200: accuracy:0.9 loss: 42.273056 (lr:0.0027240285123042826)\n",
      "200: ********* epoch 1 ********* test accuracy:0.913 test loss: 28.621822\n",
      "210: ********* epoch 1 ********* test accuracy:0.9318 test loss: 22.72701\n",
      "220: ********* epoch 1 ********* test accuracy:0.9353 test loss: 22.442467\n",
      "230: ********* epoch 1 ********* test accuracy:0.9333 test loss: 22.186888\n",
      "240: ********* epoch 1 ********* test accuracy:0.9407 test loss: 20.274397\n",
      "250: ********* epoch 1 ********* test accuracy:0.9395 test loss: 20.068968\n",
      "260: ********* epoch 1 ********* test accuracy:0.9401 test loss: 20.515411\n",
      "270: ********* epoch 1 ********* test accuracy:0.9409 test loss: 20.020216\n",
      "280: ********* epoch 1 ********* test accuracy:0.9427 test loss: 20.1915\n",
      "290: ********* epoch 1 ********* test accuracy:0.9412 test loss: 19.8428\n",
      "300: accuracy:0.93 loss: 26.63126 (lr:0.0025960531316326675)\n",
      "300: ********* epoch 1 ********* test accuracy:0.9406 test loss: 19.912413\n",
      "310: ********* epoch 1 ********* test accuracy:0.9427 test loss: 19.605259\n",
      "320: ********* epoch 1 ********* test accuracy:0.9467 test loss: 18.90884\n",
      "330: ********* epoch 1 ********* test accuracy:0.9422 test loss: 19.224619\n",
      "340: ********* epoch 1 ********* test accuracy:0.9396 test loss: 20.726873\n",
      "350: ********* epoch 1 ********* test accuracy:0.9453 test loss: 18.690168\n",
      "360: ********* epoch 1 ********* test accuracy:0.9494 test loss: 17.677065\n",
      "370: ********* epoch 1 ********* test accuracy:0.9458 test loss: 18.219683\n",
      "380: ********* epoch 1 ********* test accuracy:0.9523 test loss: 16.86572\n",
      "390: ********* epoch 1 ********* test accuracy:0.9499 test loss: 17.23731\n",
      "400: accuracy:0.93 loss: 19.94313 (lr:0.0024743191839261473)\n",
      "400: ********* epoch 1 ********* test accuracy:0.9476 test loss: 17.567448\n",
      "410: ********* epoch 1 ********* test accuracy:0.9488 test loss: 17.827253\n",
      "420: ********* epoch 1 ********* test accuracy:0.9502 test loss: 17.14705\n",
      "430: ********* epoch 1 ********* test accuracy:0.9539 test loss: 16.12636\n",
      "440: ********* epoch 1 ********* test accuracy:0.9437 test loss: 19.11633\n",
      "450: ********* epoch 1 ********* test accuracy:0.9531 test loss: 16.009613\n",
      "460: ********* epoch 1 ********* test accuracy:0.9526 test loss: 16.378736\n",
      "470: ********* epoch 1 ********* test accuracy:0.9496 test loss: 17.158138\n",
      "480: ********* epoch 1 ********* test accuracy:0.9552 test loss: 15.497567\n",
      "490: ********* epoch 1 ********* test accuracy:0.9543 test loss: 15.445126\n",
      "500: accuracy:0.96 loss: 11.523016 (lr:0.002358522270907074)\n",
      "500: ********* epoch 1 ********* test accuracy:0.954 test loss: 15.693076\n",
      "510: ********* epoch 1 ********* test accuracy:0.9556 test loss: 15.08065\n",
      "520: ********* epoch 1 ********* test accuracy:0.9545 test loss: 15.449616\n",
      "530: ********* epoch 1 ********* test accuracy:0.9567 test loss: 15.279902\n",
      "540: ********* epoch 1 ********* test accuracy:0.9539 test loss: 15.911404\n",
      "550: ********* epoch 1 ********* test accuracy:0.9522 test loss: 16.260466\n",
      "560: ********* epoch 1 ********* test accuracy:0.9568 test loss: 14.549616\n",
      "570: ********* epoch 1 ********* test accuracy:0.9557 test loss: 15.045097\n",
      "580: ********* epoch 1 ********* test accuracy:0.9527 test loss: 15.862292\n",
      "590: ********* epoch 1 ********* test accuracy:0.9599 test loss: 13.3971615\n",
      "600: accuracy:0.94 loss: 16.201748 (lr:0.002248372839976982)\n",
      "600: ********* epoch 2 ********* test accuracy:0.9597 test loss: 13.823448\n",
      "610: ********* epoch 2 ********* test accuracy:0.9608 test loss: 13.913954\n",
      "620: ********* epoch 2 ********* test accuracy:0.9574 test loss: 15.247085\n",
      "630: ********* epoch 2 ********* test accuracy:0.9605 test loss: 14.234969\n",
      "640: ********* epoch 2 ********* test accuracy:0.9611 test loss: 13.762776\n",
      "650: ********* epoch 2 ********* test accuracy:0.9598 test loss: 13.932141\n",
      "660: ********* epoch 2 ********* test accuracy:0.9603 test loss: 13.899262\n",
      "670: ********* epoch 2 ********* test accuracy:0.9595 test loss: 13.595409\n",
      "680: ********* epoch 2 ********* test accuracy:0.9568 test loss: 14.334881\n",
      "690: ********* epoch 2 ********* test accuracy:0.9596 test loss: 14.077802\n",
      "700: accuracy:0.96 loss: 14.252007 (lr:0.002143595460184269)\n",
      "700: ********* epoch 2 ********* test accuracy:0.9595 test loss: 14.135628\n",
      "710: ********* epoch 2 ********* test accuracy:0.9606 test loss: 13.442733\n",
      "720: ********* epoch 2 ********* test accuracy:0.9596 test loss: 14.143837\n",
      "730: ********* epoch 2 ********* test accuracy:0.9596 test loss: 13.989049\n",
      "740: ********* epoch 2 ********* test accuracy:0.9609 test loss: 13.514592\n",
      "750: ********* epoch 2 ********* test accuracy:0.9603 test loss: 13.790862\n",
      "760: ********* epoch 2 ********* test accuracy:0.9619 test loss: 13.393828\n",
      "770: ********* epoch 2 ********* test accuracy:0.961 test loss: 13.563594\n",
      "780: ********* epoch 2 ********* test accuracy:0.9607 test loss: 13.854801\n",
      "790: ********* epoch 2 ********* test accuracy:0.9613 test loss: 13.262916\n",
      "800: accuracy:0.94 loss: 18.48571 (lr:0.002043928133503354)\n",
      "800: ********* epoch 2 ********* test accuracy:0.9575 test loss: 14.2006235\n",
      "810: ********* epoch 2 ********* test accuracy:0.9634 test loss: 12.5633135\n",
      "820: ********* epoch 2 ********* test accuracy:0.9628 test loss: 12.749932\n",
      "830: ********* epoch 2 ********* test accuracy:0.9634 test loss: 11.9520445\n",
      "840: ********* epoch 2 ********* test accuracy:0.9634 test loss: 12.473159\n",
      "850: ********* epoch 2 ********* test accuracy:0.9632 test loss: 12.389311\n",
      "860: ********* epoch 2 ********* test accuracy:0.9615 test loss: 12.940131\n",
      "870: ********* epoch 2 ********* test accuracy:0.9656 test loss: 12.0859375\n",
      "880: ********* epoch 2 ********* test accuracy:0.9652 test loss: 12.517126\n",
      "890: ********* epoch 2 ********* test accuracy:0.9621 test loss: 13.5406885\n",
      "900: accuracy:0.99 loss: 4.519203 (lr:0.001949121639703143)\n",
      "900: ********* epoch 2 ********* test accuracy:0.964 test loss: 12.202469\n",
      "910: ********* epoch 2 ********* test accuracy:0.965 test loss: 12.461731\n",
      "920: ********* epoch 2 ********* test accuracy:0.9679 test loss: 11.72158\n",
      "930: ********* epoch 2 ********* test accuracy:0.9661 test loss: 11.463221\n",
      "940: ********* epoch 2 ********* test accuracy:0.9639 test loss: 12.663913\n",
      "950: ********* epoch 2 ********* test accuracy:0.9645 test loss: 12.111809\n",
      "960: ********* epoch 2 ********* test accuracy:0.9645 test loss: 12.23319\n",
      "970: ********* epoch 2 ********* test accuracy:0.9654 test loss: 11.859885\n",
      "980: ********* epoch 2 ********* test accuracy:0.9613 test loss: 13.188112\n",
      "990: ********* epoch 2 ********* test accuracy:0.9625 test loss: 13.120108\n",
      "1000: accuracy:0.99 loss: 3.9327912 (lr:0.0018589389131666372)\n",
      "1000: ********* epoch 2 ********* test accuracy:0.9658 test loss: 11.577021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010: ********* epoch 2 ********* test accuracy:0.9659 test loss: 11.711864\n",
      "1020: ********* epoch 2 ********* test accuracy:0.9665 test loss: 11.720888\n",
      "1030: ********* epoch 2 ********* test accuracy:0.9685 test loss: 11.621931\n",
      "1040: ********* epoch 2 ********* test accuracy:0.9688 test loss: 11.297734\n",
      "1050: ********* epoch 2 ********* test accuracy:0.968 test loss: 11.581103\n",
      "1060: ********* epoch 2 ********* test accuracy:0.9671 test loss: 11.602927\n",
      "1070: ********* epoch 2 ********* test accuracy:0.9641 test loss: 12.489472\n",
      "1080: ********* epoch 2 ********* test accuracy:0.9664 test loss: 11.792702\n",
      "1090: ********* epoch 2 ********* test accuracy:0.9636 test loss: 12.62788\n",
      "1100: accuracy:0.96 loss: 9.705142 (lr:0.0017731544501034114)\n",
      "1100: ********* epoch 2 ********* test accuracy:0.9667 test loss: 11.285608\n",
      "1110: ********* epoch 2 ********* test accuracy:0.9656 test loss: 11.688295\n",
      "1120: ********* epoch 2 ********* test accuracy:0.9661 test loss: 11.622091\n",
      "1130: ********* epoch 2 ********* test accuracy:0.9667 test loss: 11.452568\n",
      "1140: ********* epoch 2 ********* test accuracy:0.969 test loss: 10.565964\n",
      "1150: ********* epoch 2 ********* test accuracy:0.9688 test loss: 10.598721\n",
      "1160: ********* epoch 2 ********* test accuracy:0.9673 test loss: 11.320404\n",
      "1170: ********* epoch 2 ********* test accuracy:0.9711 test loss: 10.8155365\n",
      "1180: ********* epoch 2 ********* test accuracy:0.9709 test loss: 10.680259\n",
      "1190: ********* epoch 2 ********* test accuracy:0.9694 test loss: 10.77342\n",
      "1200: accuracy:0.98 loss: 5.5290356 (lr:0.001691553744672677)\n",
      "1200: ********* epoch 3 ********* test accuracy:0.9667 test loss: 11.606331\n",
      "1210: ********* epoch 3 ********* test accuracy:0.9681 test loss: 11.330028\n",
      "1220: ********* epoch 3 ********* test accuracy:0.9696 test loss: 10.857886\n",
      "1230: ********* epoch 3 ********* test accuracy:0.9706 test loss: 10.6115675\n",
      "1240: ********* epoch 3 ********* test accuracy:0.9669 test loss: 11.472728\n",
      "1250: ********* epoch 3 ********* test accuracy:0.9688 test loss: 11.2363\n",
      "1260: ********* epoch 3 ********* test accuracy:0.9693 test loss: 11.067143\n",
      "1270: ********* epoch 3 ********* test accuracy:0.9703 test loss: 10.658723\n",
      "1280: ********* epoch 3 ********* test accuracy:0.9691 test loss: 10.998721\n",
      "1290: ********* epoch 3 ********* test accuracy:0.968 test loss: 11.052243\n",
      "1300: accuracy:0.96 loss: 15.990676 (lr:0.0016139327526069466)\n",
      "1300: ********* epoch 3 ********* test accuracy:0.97 test loss: 10.715161\n",
      "1310: ********* epoch 3 ********* test accuracy:0.9708 test loss: 10.747393\n",
      "1320: ********* epoch 3 ********* test accuracy:0.9715 test loss: 10.544138\n",
      "1330: ********* epoch 3 ********* test accuracy:0.9706 test loss: 10.220913\n",
      "1340: ********* epoch 3 ********* test accuracy:0.9708 test loss: 10.340063\n",
      "1350: ********* epoch 3 ********* test accuracy:0.9717 test loss: 10.223542\n",
      "1360: ********* epoch 3 ********* test accuracy:0.9714 test loss: 10.6331215\n",
      "1370: ********* epoch 3 ********* test accuracy:0.9709 test loss: 10.454657\n",
      "1380: ********* epoch 3 ********* test accuracy:0.9708 test loss: 10.328135\n",
      "1390: ********* epoch 3 ********* test accuracy:0.9697 test loss: 10.4317\n",
      "1400: accuracy:0.99 loss: 7.435456 (lr:0.0015400973809950877)\n",
      "1400: ********* epoch 3 ********* test accuracy:0.9705 test loss: 10.554901\n",
      "1410: ********* epoch 3 ********* test accuracy:0.9705 test loss: 10.359203\n",
      "1420: ********* epoch 3 ********* test accuracy:0.9701 test loss: 10.239976\n",
      "1430: ********* epoch 3 ********* test accuracy:0.9712 test loss: 10.237158\n",
      "1440: ********* epoch 3 ********* test accuracy:0.9694 test loss: 10.869958\n",
      "1450: ********* epoch 3 ********* test accuracy:0.9675 test loss: 11.185373\n",
      "1460: ********* epoch 3 ********* test accuracy:0.9694 test loss: 10.855902\n",
      "1470: ********* epoch 3 ********* test accuracy:0.9712 test loss: 10.15353\n",
      "1480: ********* epoch 3 ********* test accuracy:0.9704 test loss: 10.556199\n",
      "1490: ********* epoch 3 ********* test accuracy:0.9709 test loss: 10.514206\n",
      "1500: accuracy:0.98 loss: 9.103963 (lr:0.0014698630029489428)\n",
      "1500: ********* epoch 3 ********* test accuracy:0.9706 test loss: 10.049167\n",
      "1510: ********* epoch 3 ********* test accuracy:0.9699 test loss: 10.414503\n",
      "1520: ********* epoch 3 ********* test accuracy:0.9713 test loss: 10.335506\n",
      "1530: ********* epoch 3 ********* test accuracy:0.971 test loss: 10.30778\n",
      "1540: ********* epoch 3 ********* test accuracy:0.9712 test loss: 10.264188\n",
      "1550: ********* epoch 3 ********* test accuracy:0.9709 test loss: 9.912481\n",
      "1560: ********* epoch 3 ********* test accuracy:0.972 test loss: 10.1955\n",
      "1570: ********* epoch 3 ********* test accuracy:0.9714 test loss: 10.310815\n",
      "1580: ********* epoch 3 ********* test accuracy:0.9699 test loss: 10.797435\n",
      "1590: ********* epoch 3 ********* test accuracy:0.9729 test loss: 9.878119\n",
      "1600: accuracy:0.99 loss: 3.8092456 (lr:0.0014030539959399427)\n",
      "1600: ********* epoch 3 ********* test accuracy:0.9711 test loss: 10.413768\n",
      "1610: ********* epoch 3 ********* test accuracy:0.9717 test loss: 9.791758\n",
      "1620: ********* epoch 3 ********* test accuracy:0.9728 test loss: 9.255643\n",
      "1630: ********* epoch 3 ********* test accuracy:0.9716 test loss: 9.832933\n",
      "1640: ********* epoch 3 ********* test accuracy:0.9708 test loss: 10.355852\n",
      "1650: ********* epoch 3 ********* test accuracy:0.9677 test loss: 11.26217\n",
      "1660: ********* epoch 3 ********* test accuracy:0.9708 test loss: 9.953138\n",
      "1670: ********* epoch 3 ********* test accuracy:0.9695 test loss: 10.017673\n",
      "1680: ********* epoch 3 ********* test accuracy:0.9697 test loss: 10.370828\n",
      "1690: ********* epoch 3 ********* test accuracy:0.9723 test loss: 9.848718\n",
      "1700: accuracy:0.97 loss: 14.779164 (lr:0.0013395033026513076)\n",
      "1700: ********* epoch 3 ********* test accuracy:0.9734 test loss: 9.628737\n",
      "1710: ********* epoch 3 ********* test accuracy:0.9724 test loss: 9.683969\n",
      "1720: ********* epoch 3 ********* test accuracy:0.9714 test loss: 9.798039\n",
      "1730: ********* epoch 3 ********* test accuracy:0.9712 test loss: 9.745658\n",
      "1740: ********* epoch 3 ********* test accuracy:0.9724 test loss: 9.974684\n",
      "1750: ********* epoch 3 ********* test accuracy:0.9708 test loss: 9.989749\n",
      "1760: ********* epoch 3 ********* test accuracy:0.9701 test loss: 9.9963\n",
      "1770: ********* epoch 3 ********* test accuracy:0.9719 test loss: 9.551807\n",
      "1780: ********* epoch 3 ********* test accuracy:0.97 test loss: 9.992908\n",
      "1790: ********* epoch 3 ********* test accuracy:0.973 test loss: 9.227243\n",
      "1800: accuracy:0.97 loss: 9.214819 (lr:0.0012790520132477375)\n",
      "1800: ********* epoch 4 ********* test accuracy:0.9717 test loss: 9.182473\n",
      "1810: ********* epoch 4 ********* test accuracy:0.9722 test loss: 9.405819\n",
      "1820: ********* epoch 4 ********* test accuracy:0.9723 test loss: 9.433758\n",
      "1830: ********* epoch 4 ********* test accuracy:0.9724 test loss: 9.343286\n",
      "1840: ********* epoch 4 ********* test accuracy:0.9711 test loss: 10.079686\n",
      "1850: ********* epoch 4 ********* test accuracy:0.9733 test loss: 9.680509\n",
      "1860: ********* epoch 4 ********* test accuracy:0.9733 test loss: 9.136745\n",
      "1870: ********* epoch 4 ********* test accuracy:0.9726 test loss: 9.372692\n",
      "1880: ********* epoch 4 ********* test accuracy:0.9729 test loss: 9.315263\n",
      "1890: ********* epoch 4 ********* test accuracy:0.9726 test loss: 8.972535\n",
      "1900: accuracy:0.97 loss: 9.197429 (lr:0.0012215489680180538)\n",
      "1900: ********* epoch 4 ********* test accuracy:0.9715 test loss: 9.679987\n",
      "1910: ********* epoch 4 ********* test accuracy:0.9725 test loss: 9.246494\n",
      "1920: ********* epoch 4 ********* test accuracy:0.9732 test loss: 8.951209\n",
      "1930: ********* epoch 4 ********* test accuracy:0.9722 test loss: 9.289056\n",
      "1940: ********* epoch 4 ********* test accuracy:0.9731 test loss: 9.053068\n",
      "1950: ********* epoch 4 ********* test accuracy:0.9731 test loss: 9.308423\n",
      "1960: ********* epoch 4 ********* test accuracy:0.9732 test loss: 9.235128\n",
      "1970: ********* epoch 4 ********* test accuracy:0.9744 test loss: 8.960817\n",
      "1980: ********* epoch 4 ********* test accuracy:0.9735 test loss: 9.074994\n",
      "1990: ********* epoch 4 ********* test accuracy:0.974 test loss: 9.07242\n",
      "2000: accuracy:0.96 loss: 16.444416 (lr:0.0011668503793971828)\n",
      "2000: ********* epoch 4 ********* test accuracy:0.9744 test loss: 8.667136\n",
      "2010: ********* epoch 4 ********* test accuracy:0.9746 test loss: 8.697535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: ********* epoch 4 ********* test accuracy:0.9748 test loss: 8.554064\n",
      "2030: ********* epoch 4 ********* test accuracy:0.9743 test loss: 9.387408\n",
      "2040: ********* epoch 4 ********* test accuracy:0.9742 test loss: 8.927876\n",
      "2050: ********* epoch 4 ********* test accuracy:0.9742 test loss: 8.761261\n",
      "2060: ********* epoch 4 ********* test accuracy:0.9737 test loss: 8.900101\n",
      "2070: ********* epoch 4 ********* test accuracy:0.9738 test loss: 8.8625\n",
      "2080: ********* epoch 4 ********* test accuracy:0.9731 test loss: 9.138311\n",
      "2090: ********* epoch 4 ********* test accuracy:0.9725 test loss: 9.292268\n",
      "2100: accuracy:1.0 loss: 0.9514426 (lr:0.0011148194724223506)\n",
      "2100: ********* epoch 4 ********* test accuracy:0.9718 test loss: 9.467469\n",
      "2110: ********* epoch 4 ********* test accuracy:0.9727 test loss: 9.273138\n",
      "2120: ********* epoch 4 ********* test accuracy:0.9739 test loss: 8.85366\n",
      "2130: ********* epoch 4 ********* test accuracy:0.9748 test loss: 8.660856\n",
      "2140: ********* epoch 4 ********* test accuracy:0.975 test loss: 8.411936\n",
      "2150: ********* epoch 4 ********* test accuracy:0.9744 test loss: 8.322777\n",
      "2160: ********* epoch 4 ********* test accuracy:0.9743 test loss: 8.4555\n",
      "2170: ********* epoch 4 ********* test accuracy:0.9748 test loss: 8.809266\n",
      "2180: ********* epoch 4 ********* test accuracy:0.9753 test loss: 8.328504\n",
      "2190: ********* epoch 4 ********* test accuracy:0.9753 test loss: 8.594214\n",
      "2200: accuracy:0.99 loss: 2.4655843 (lr:0.0010653261427244307)\n",
      "2200: ********* epoch 4 ********* test accuracy:0.9765 test loss: 8.33867\n",
      "2210: ********* epoch 4 ********* test accuracy:0.9749 test loss: 8.255844\n",
      "2220: ********* epoch 4 ********* test accuracy:0.9742 test loss: 8.664734\n",
      "2230: ********* epoch 4 ********* test accuracy:0.9751 test loss: 8.617995\n",
      "2240: ********* epoch 4 ********* test accuracy:0.9759 test loss: 8.6465435\n",
      "2250: ********* epoch 4 ********* test accuracy:0.976 test loss: 8.5401325\n",
      "2260: ********* epoch 4 ********* test accuracy:0.9757 test loss: 8.663799\n",
      "2270: ********* epoch 4 ********* test accuracy:0.9762 test loss: 8.312477\n",
      "2280: ********* epoch 4 ********* test accuracy:0.9767 test loss: 8.211799\n",
      "2290: ********* epoch 4 ********* test accuracy:0.9756 test loss: 8.336973\n",
      "2300: accuracy:0.97 loss: 7.146976 (lr:0.0010182466311992545)\n",
      "2300: ********* epoch 4 ********* test accuracy:0.9754 test loss: 8.501338\n",
      "2310: ********* epoch 4 ********* test accuracy:0.9748 test loss: 8.8144455\n",
      "2320: ********* epoch 4 ********* test accuracy:0.9755 test loss: 8.3389\n",
      "2330: ********* epoch 4 ********* test accuracy:0.9754 test loss: 8.523647\n",
      "2340: ********* epoch 4 ********* test accuracy:0.975 test loss: 8.321281\n",
      "2350: ********* epoch 4 ********* test accuracy:0.9755 test loss: 8.301069\n",
      "2360: ********* epoch 4 ********* test accuracy:0.9761 test loss: 8.280346\n",
      "2370: ********* epoch 4 ********* test accuracy:0.9751 test loss: 8.615952\n",
      "2380: ********* epoch 4 ********* test accuracy:0.9767 test loss: 8.203282\n",
      "2390: ********* epoch 4 ********* test accuracy:0.9764 test loss: 8.163852\n",
      "2400: accuracy:0.96 loss: 12.144247 (lr:0.0009734632145453863)\n",
      "2400: ********* epoch 5 ********* test accuracy:0.9763 test loss: 8.453117\n",
      "2410: ********* epoch 5 ********* test accuracy:0.9762 test loss: 8.390515\n",
      "2420: ********* epoch 5 ********* test accuracy:0.977 test loss: 8.073131\n",
      "2430: ********* epoch 5 ********* test accuracy:0.9782 test loss: 7.9504757\n",
      "2440: ********* epoch 5 ********* test accuracy:0.9768 test loss: 7.890794\n",
      "2450: ********* epoch 5 ********* test accuracy:0.976 test loss: 8.110271\n",
      "2460: ********* epoch 5 ********* test accuracy:0.9756 test loss: 8.280869\n",
      "2470: ********* epoch 5 ********* test accuracy:0.9767 test loss: 8.258476\n",
      "2480: ********* epoch 5 ********* test accuracy:0.9769 test loss: 8.548123\n",
      "2490: ********* epoch 5 ********* test accuracy:0.9764 test loss: 8.299751\n",
      "2500: accuracy:0.98 loss: 6.503334 (lr:0.0009308639108945514)\n",
      "2500: ********* epoch 5 ********* test accuracy:0.9763 test loss: 8.149372\n",
      "2510: ********* epoch 5 ********* test accuracy:0.9762 test loss: 8.365613\n",
      "2520: ********* epoch 5 ********* test accuracy:0.9755 test loss: 8.448921\n",
      "2530: ********* epoch 5 ********* test accuracy:0.9753 test loss: 8.577539\n",
      "2540: ********* epoch 5 ********* test accuracy:0.9755 test loss: 8.715687\n",
      "2550: ********* epoch 5 ********* test accuracy:0.9764 test loss: 8.463005\n",
      "2560: ********* epoch 5 ********* test accuracy:0.9755 test loss: 8.880825\n",
      "2570: ********* epoch 5 ********* test accuracy:0.9756 test loss: 8.825918\n",
      "2580: ********* epoch 5 ********* test accuracy:0.9749 test loss: 8.793612\n",
      "2590: ********* epoch 5 ********* test accuracy:0.9753 test loss: 8.83699\n",
      "2600: accuracy:0.98 loss: 4.4656577 (lr:0.0008903421997986366)\n",
      "2600: ********* epoch 5 ********* test accuracy:0.9751 test loss: 9.171753\n",
      "2610: ********* epoch 5 ********* test accuracy:0.9747 test loss: 9.212584\n",
      "2620: ********* epoch 5 ********* test accuracy:0.9752 test loss: 8.9184\n",
      "2630: ********* epoch 5 ********* test accuracy:0.9751 test loss: 8.914335\n",
      "2640: ********* epoch 5 ********* test accuracy:0.9763 test loss: 8.514975\n",
      "2650: ********* epoch 5 ********* test accuracy:0.9764 test loss: 8.282745\n",
      "2660: ********* epoch 5 ********* test accuracy:0.9769 test loss: 8.18597\n",
      "2670: ********* epoch 5 ********* test accuracy:0.9762 test loss: 8.374972\n",
      "2680: ********* epoch 5 ********* test accuracy:0.9751 test loss: 8.826833\n",
      "2690: ********* epoch 5 ********* test accuracy:0.9751 test loss: 8.784642\n",
      "2700: accuracy:0.97 loss: 5.5152426 (lr:0.0008517967558730855)\n",
      "2700: ********* epoch 5 ********* test accuracy:0.9752 test loss: 8.807483\n",
      "2710: ********* epoch 5 ********* test accuracy:0.9765 test loss: 8.33929\n",
      "2720: ********* epoch 5 ********* test accuracy:0.9753 test loss: 8.4934025\n",
      "2730: ********* epoch 5 ********* test accuracy:0.9751 test loss: 8.661862\n",
      "2740: ********* epoch 5 ********* test accuracy:0.9767 test loss: 8.501401\n",
      "2750: ********* epoch 5 ********* test accuracy:0.9771 test loss: 8.56632\n",
      "2760: ********* epoch 5 ********* test accuracy:0.9772 test loss: 8.483293\n",
      "2770: ********* epoch 5 ********* test accuracy:0.977 test loss: 8.214194\n",
      "2780: ********* epoch 5 ********* test accuracy:0.977 test loss: 8.2507715\n",
      "2790: ********* epoch 5 ********* test accuracy:0.9771 test loss: 8.212685\n",
      "2800: accuracy:1.0 loss: 1.2660682 (lr:0.0008151311954306589)\n",
      "2800: ********* epoch 5 ********* test accuracy:0.9771 test loss: 8.140087\n",
      "2810: ********* epoch 5 ********* test accuracy:0.9762 test loss: 8.168181\n",
      "2820: ********* epoch 5 ********* test accuracy:0.9759 test loss: 8.267519\n",
      "2830: ********* epoch 5 ********* test accuracy:0.9764 test loss: 8.266277\n",
      "2840: ********* epoch 5 ********* test accuracy:0.976 test loss: 8.278665\n",
      "2850: ********* epoch 5 ********* test accuracy:0.9763 test loss: 8.152974\n",
      "2860: ********* epoch 5 ********* test accuracy:0.9767 test loss: 8.038833\n",
      "2870: ********* epoch 5 ********* test accuracy:0.9766 test loss: 7.8578324\n",
      "2880: ********* epoch 5 ********* test accuracy:0.9773 test loss: 7.8618197\n",
      "2890: ********* epoch 5 ********* test accuracy:0.977 test loss: 7.6891317\n",
      "2900: accuracy:1.0 loss: 0.5927516 (lr:0.0007802538354720133)\n",
      "2900: ********* epoch 5 ********* test accuracy:0.977 test loss: 7.774565\n",
      "2910: ********* epoch 5 ********* test accuracy:0.9766 test loss: 7.935001\n",
      "2920: ********* epoch 5 ********* test accuracy:0.9764 test loss: 7.8796\n",
      "2930: ********* epoch 5 ********* test accuracy:0.9775 test loss: 7.7991076\n",
      "2940: ********* epoch 5 ********* test accuracy:0.9764 test loss: 7.900385\n",
      "2950: ********* epoch 5 ********* test accuracy:0.9768 test loss: 7.9217377\n",
      "2960: ********* epoch 5 ********* test accuracy:0.9772 test loss: 7.864834\n",
      "2970: ********* epoch 5 ********* test accuracy:0.9785 test loss: 7.689476\n",
      "2980: ********* epoch 5 ********* test accuracy:0.9781 test loss: 7.6780176\n",
      "2990: ********* epoch 5 ********* test accuracy:0.9775 test loss: 7.6564918\n",
      "3000: accuracy:0.98 loss: 2.670812 (lr:0.0007470774644304465)\n",
      "3000: ********* epoch 6 ********* test accuracy:0.977 test loss: 7.771378\n",
      "3010: ********* epoch 6 ********* test accuracy:0.9761 test loss: 7.98578\n",
      "3020: ********* epoch 6 ********* test accuracy:0.977 test loss: 7.9914784\n",
      "3030: ********* epoch 6 ********* test accuracy:0.9765 test loss: 7.974668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3040: ********* epoch 6 ********* test accuracy:0.9762 test loss: 8.146679\n",
      "3050: ********* epoch 6 ********* test accuracy:0.977 test loss: 8.258582\n",
      "3060: ********* epoch 6 ********* test accuracy:0.9769 test loss: 8.284016\n",
      "3070: ********* epoch 6 ********* test accuracy:0.9761 test loss: 8.44173\n",
      "3080: ********* epoch 6 ********* test accuracy:0.977 test loss: 8.162551\n",
      "3090: ********* epoch 6 ********* test accuracy:0.9778 test loss: 8.068859\n",
      "3100: accuracy:0.98 loss: 4.1905513 (lr:0.0007155191240975549)\n",
      "3100: ********* epoch 6 ********* test accuracy:0.9771 test loss: 8.213913\n",
      "3110: ********* epoch 6 ********* test accuracy:0.9766 test loss: 8.394674\n",
      "3120: ********* epoch 6 ********* test accuracy:0.9773 test loss: 8.383512\n",
      "3130: ********* epoch 6 ********* test accuracy:0.9764 test loss: 8.256912\n",
      "3140: ********* epoch 6 ********* test accuracy:0.9767 test loss: 7.9956226\n",
      "3150: ********* epoch 6 ********* test accuracy:0.9774 test loss: 7.9452157\n",
      "3160: ********* epoch 6 ********* test accuracy:0.9772 test loss: 7.8701863\n",
      "3170: ********* epoch 6 ********* test accuracy:0.9787 test loss: 7.657977\n",
      "3180: ********* epoch 6 ********* test accuracy:0.9787 test loss: 7.7427535\n",
      "3190: ********* epoch 6 ********* test accuracy:0.9787 test loss: 7.796888\n",
      "3200: accuracy:0.99 loss: 4.7764153 (lr:0.0006854999021845007)\n",
      "3200: ********* epoch 6 ********* test accuracy:0.9789 test loss: 7.7013464\n",
      "3210: ********* epoch 6 ********* test accuracy:0.9792 test loss: 7.7353067\n",
      "3220: ********* epoch 6 ********* test accuracy:0.9794 test loss: 7.632417\n",
      "3230: ********* epoch 6 ********* test accuracy:0.9793 test loss: 7.731406\n",
      "3240: ********* epoch 6 ********* test accuracy:0.979 test loss: 7.816188\n",
      "3250: ********* epoch 6 ********* test accuracy:0.9792 test loss: 7.734052\n",
      "3260: ********* epoch 6 ********* test accuracy:0.9777 test loss: 8.052639\n",
      "3270: ********* epoch 6 ********* test accuracy:0.9781 test loss: 7.906016\n",
      "3280: ********* epoch 6 ********* test accuracy:0.9789 test loss: 7.7994747\n",
      "3290: ********* epoch 6 ********* test accuracy:0.9783 test loss: 7.999935\n",
      "3300: accuracy:0.99 loss: 2.3647704 (lr:0.000656944735000187)\n",
      "3300: ********* epoch 6 ********* test accuracy:0.9784 test loss: 7.866008\n",
      "3310: ********* epoch 6 ********* test accuracy:0.978 test loss: 8.019045\n",
      "3320: ********* epoch 6 ********* test accuracy:0.9778 test loss: 8.007739\n",
      "3330: ********* epoch 6 ********* test accuracy:0.9786 test loss: 7.789816\n",
      "3340: ********* epoch 6 ********* test accuracy:0.9789 test loss: 7.72155\n",
      "3350: ********* epoch 6 ********* test accuracy:0.9789 test loss: 7.5055933\n",
      "3360: ********* epoch 6 ********* test accuracy:0.9789 test loss: 7.4362993\n",
      "3370: ********* epoch 6 ********* test accuracy:0.979 test loss: 7.403098\n",
      "3380: ********* epoch 6 ********* test accuracy:0.9793 test loss: 7.1966915\n",
      "3390: ********* epoch 6 ********* test accuracy:0.9794 test loss: 7.2472997\n",
      "3400: accuracy:0.97 loss: 18.117657 (lr:0.0006297822197529307)\n",
      "3400: ********* epoch 6 ********* test accuracy:0.9794 test loss: 7.3480034\n",
      "3410: ********* epoch 6 ********* test accuracy:0.9799 test loss: 7.2588563\n",
      "3420: ********* epoch 6 ********* test accuracy:0.9796 test loss: 7.2627873\n",
      "3430: ********* epoch 6 ********* test accuracy:0.9794 test loss: 7.445285\n",
      "3440: ********* epoch 6 ********* test accuracy:0.9793 test loss: 7.5010986\n",
      "3450: ********* epoch 6 ********* test accuracy:0.9791 test loss: 7.5676537\n",
      "3460: ********* epoch 6 ********* test accuracy:0.9795 test loss: 7.539214\n",
      "3470: ********* epoch 6 ********* test accuracy:0.9792 test loss: 7.5538435\n",
      "3480: ********* epoch 6 ********* test accuracy:0.9786 test loss: 7.6632795\n",
      "3490: ********* epoch 6 ********* test accuracy:0.9795 test loss: 7.804616\n",
      "3500: accuracy:0.99 loss: 2.3108635 (lr:0.000603944436006291)\n",
      "3500: ********* epoch 6 ********* test accuracy:0.979 test loss: 7.907212\n",
      "3510: ********* epoch 6 ********* test accuracy:0.9795 test loss: 7.8933573\n",
      "3520: ********* epoch 6 ********* test accuracy:0.9793 test loss: 7.906119\n",
      "3530: ********* epoch 6 ********* test accuracy:0.9788 test loss: 8.0069895\n",
      "3540: ********* epoch 6 ********* test accuracy:0.979 test loss: 7.885585\n",
      "3550: ********* epoch 6 ********* test accuracy:0.9785 test loss: 7.8221755\n",
      "3560: ********* epoch 6 ********* test accuracy:0.9779 test loss: 7.8954377\n",
      "3570: ********* epoch 6 ********* test accuracy:0.9787 test loss: 7.842712\n",
      "3580: ********* epoch 6 ********* test accuracy:0.9792 test loss: 7.8304195\n",
      "3590: ********* epoch 6 ********* test accuracy:0.9786 test loss: 7.907267\n",
      "3600: accuracy:1.0 loss: 0.6062843 (lr:0.000579366775842601)\n",
      "3600: ********* epoch 7 ********* test accuracy:0.9783 test loss: 7.9630995\n",
      "3610: ********* epoch 7 ********* test accuracy:0.9786 test loss: 7.756015\n",
      "3620: ********* epoch 7 ********* test accuracy:0.9785 test loss: 7.742091\n",
      "3630: ********* epoch 7 ********* test accuracy:0.9785 test loss: 7.8203\n",
      "3640: ********* epoch 7 ********* test accuracy:0.9786 test loss: 7.857091\n",
      "3650: ********* epoch 7 ********* test accuracy:0.9788 test loss: 7.8612385\n",
      "3660: ********* epoch 7 ********* test accuracy:0.9789 test loss: 7.907825\n",
      "3670: ********* epoch 7 ********* test accuracy:0.9784 test loss: 7.8896294\n",
      "3680: ********* epoch 7 ********* test accuracy:0.9772 test loss: 8.169368\n",
      "3690: ********* epoch 7 ********* test accuracy:0.9782 test loss: 8.000605\n",
      "3700: accuracy:0.99 loss: 2.7548687 (lr:0.0005559877823095201)\n",
      "3700: ********* epoch 7 ********* test accuracy:0.9783 test loss: 8.0263605\n",
      "3710: ********* epoch 7 ********* test accuracy:0.9787 test loss: 7.9825664\n",
      "3720: ********* epoch 7 ********* test accuracy:0.9786 test loss: 7.7126374\n",
      "3730: ********* epoch 7 ********* test accuracy:0.9778 test loss: 7.678774\n",
      "3740: ********* epoch 7 ********* test accuracy:0.9785 test loss: 7.678216\n",
      "3750: ********* epoch 7 ********* test accuracy:0.9781 test loss: 7.8088856\n",
      "3760: ********* epoch 7 ********* test accuracy:0.9781 test loss: 7.8318453\n",
      "3770: ********* epoch 7 ********* test accuracy:0.9791 test loss: 7.841283\n",
      "3780: ********* epoch 7 ********* test accuracy:0.9789 test loss: 7.874302\n",
      "3790: ********* epoch 7 ********* test accuracy:0.9785 test loss: 7.8903785\n",
      "3800: accuracy:0.99 loss: 1.312441 (lr:0.0005337489957456418)\n",
      "3800: ********* epoch 7 ********* test accuracy:0.9784 test loss: 7.9710574\n",
      "3810: ********* epoch 7 ********* test accuracy:0.9783 test loss: 7.961248\n",
      "3820: ********* epoch 7 ********* test accuracy:0.9784 test loss: 7.8452244\n",
      "3830: ********* epoch 7 ********* test accuracy:0.9785 test loss: 7.829617\n",
      "3840: ********* epoch 7 ********* test accuracy:0.9777 test loss: 7.8434997\n",
      "3850: ********* epoch 7 ********* test accuracy:0.9779 test loss: 8.006013\n",
      "3860: ********* epoch 7 ********* test accuracy:0.9773 test loss: 8.207946\n",
      "3870: ********* epoch 7 ********* test accuracy:0.9779 test loss: 8.00589\n",
      "3880: ********* epoch 7 ********* test accuracy:0.9788 test loss: 7.896769\n",
      "3890: ********* epoch 7 ********* test accuracy:0.9781 test loss: 7.994759\n",
      "3900: accuracy:1.0 loss: 0.22343504 (lr:0.0005125948076008895)\n",
      "3900: ********* epoch 7 ********* test accuracy:0.9791 test loss: 7.637591\n",
      "3910: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.540781\n",
      "3920: ********* epoch 7 ********* test accuracy:0.9788 test loss: 7.597269\n",
      "3930: ********* epoch 7 ********* test accuracy:0.9793 test loss: 7.781238\n",
      "3940: ********* epoch 7 ********* test accuracy:0.9795 test loss: 7.759256\n",
      "3950: ********* epoch 7 ********* test accuracy:0.9789 test loss: 7.82056\n",
      "3960: ********* epoch 7 ********* test accuracy:0.9788 test loss: 8.077744\n",
      "3970: ********* epoch 7 ********* test accuracy:0.9779 test loss: 8.152796\n",
      "3980: ********* epoch 7 ********* test accuracy:0.9783 test loss: 8.106358\n",
      "3990: ********* epoch 7 ********* test accuracy:0.9795 test loss: 7.989612\n",
      "4000: accuracy:0.97 loss: 9.396275 (lr:0.0004924723213861769)\n",
      "4000: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.801196\n",
      "4010: ********* epoch 7 ********* test accuracy:0.9796 test loss: 7.621054\n",
      "4020: ********* epoch 7 ********* test accuracy:0.9799 test loss: 7.568737\n",
      "4030: ********* epoch 7 ********* test accuracy:0.9797 test loss: 7.589878\n",
      "4040: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.667078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4050: ********* epoch 7 ********* test accuracy:0.9795 test loss: 7.733927\n",
      "4060: ********* epoch 7 ********* test accuracy:0.9791 test loss: 7.7002516\n",
      "4070: ********* epoch 7 ********* test accuracy:0.9796 test loss: 7.688669\n",
      "4080: ********* epoch 7 ********* test accuracy:0.9803 test loss: 7.7359953\n",
      "4090: ********* epoch 7 ********* test accuracy:0.98 test loss: 7.6766105\n",
      "4100: accuracy:1.0 loss: 0.2066074 (lr:0.0004733312204046323)\n",
      "4100: ********* epoch 7 ********* test accuracy:0.9793 test loss: 7.628789\n",
      "4110: ********* epoch 7 ********* test accuracy:0.9789 test loss: 7.6119156\n",
      "4120: ********* epoch 7 ********* test accuracy:0.9797 test loss: 7.5176992\n",
      "4130: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.4953566\n",
      "4140: ********* epoch 7 ********* test accuracy:0.9793 test loss: 7.5741396\n",
      "4150: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.6587744\n",
      "4160: ********* epoch 7 ********* test accuracy:0.9798 test loss: 7.4683824\n",
      "4170: ********* epoch 7 ********* test accuracy:0.98 test loss: 7.4098988\n",
      "4180: ********* epoch 7 ********* test accuracy:0.9793 test loss: 7.506145\n",
      "4190: ********* epoch 7 ********* test accuracy:0.9794 test loss: 7.5208387\n",
      "4200: accuracy:1.0 loss: 1.1499507 (lr:0.00045512364193364755)\n",
      "4200: ********* epoch 8 ********* test accuracy:0.9792 test loss: 7.4994326\n",
      "4210: ********* epoch 8 ********* test accuracy:0.9794 test loss: 7.571129\n",
      "4220: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.5434966\n",
      "4230: ********* epoch 8 ********* test accuracy:0.9799 test loss: 7.5229607\n",
      "4240: ********* epoch 8 ********* test accuracy:0.9796 test loss: 7.527759\n",
      "4250: ********* epoch 8 ********* test accuracy:0.9794 test loss: 7.57624\n",
      "4260: ********* epoch 8 ********* test accuracy:0.9787 test loss: 7.6121426\n",
      "4270: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.64288\n",
      "4280: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.70529\n",
      "4290: ********* epoch 8 ********* test accuracy:0.9796 test loss: 7.683072\n",
      "4300: accuracy:1.0 loss: 0.598459 (lr:0.00043780405754314123)\n",
      "4300: ********* epoch 8 ********* test accuracy:0.9801 test loss: 7.5045166\n",
      "4310: ********* epoch 8 ********* test accuracy:0.9794 test loss: 7.4631615\n",
      "4320: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.623367\n",
      "4330: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.5957537\n",
      "4340: ********* epoch 8 ********* test accuracy:0.9796 test loss: 7.5805545\n",
      "4350: ********* epoch 8 ********* test accuracy:0.9788 test loss: 7.6953607\n",
      "4360: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.7235026\n",
      "4370: ********* epoch 8 ********* test accuracy:0.9796 test loss: 7.677903\n",
      "4380: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.596473\n",
      "4390: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.4879313\n",
      "4400: accuracy:0.99 loss: 4.696216 (lr:0.00042132915925076824)\n",
      "4400: ********* epoch 8 ********* test accuracy:0.9791 test loss: 7.589712\n",
      "4410: ********* epoch 8 ********* test accuracy:0.98 test loss: 7.5196652\n",
      "4420: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.5664163\n",
      "4430: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.728635\n",
      "4440: ********* epoch 8 ********* test accuracy:0.9788 test loss: 7.7778845\n",
      "4450: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.585483\n",
      "4460: ********* epoch 8 ********* test accuracy:0.9799 test loss: 7.448827\n",
      "4470: ********* epoch 8 ********* test accuracy:0.9804 test loss: 7.4182115\n",
      "4480: ********* epoch 8 ********* test accuracy:0.9807 test loss: 7.4470797\n",
      "4490: ********* epoch 8 ********* test accuracy:0.9805 test loss: 7.3773255\n",
      "4500: accuracy:1.0 loss: 0.66618764 (lr:0.00040565775122940656)\n",
      "4500: ********* epoch 8 ********* test accuracy:0.9808 test loss: 7.3114266\n",
      "4510: ********* epoch 8 ********* test accuracy:0.9807 test loss: 7.279281\n",
      "4520: ********* epoch 8 ********* test accuracy:0.9801 test loss: 7.386304\n",
      "4530: ********* epoch 8 ********* test accuracy:0.9803 test loss: 7.4945426\n",
      "4540: ********* epoch 8 ********* test accuracy:0.9799 test loss: 7.5016007\n",
      "4550: ********* epoch 8 ********* test accuracy:0.9795 test loss: 7.5038457\n",
      "4560: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.6408186\n",
      "4570: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.7332354\n",
      "4580: ********* epoch 8 ********* test accuracy:0.9799 test loss: 7.663651\n",
      "4590: ********* epoch 8 ********* test accuracy:0.9806 test loss: 7.5050297\n",
      "4600: accuracy:1.0 loss: 0.35017797 (lr:0.0003907506467961309)\n",
      "4600: ********* epoch 8 ********* test accuracy:0.9802 test loss: 7.521253\n",
      "4610: ********* epoch 8 ********* test accuracy:0.98 test loss: 7.50745\n",
      "4620: ********* epoch 8 ********* test accuracy:0.9808 test loss: 7.5406117\n",
      "4630: ********* epoch 8 ********* test accuracy:0.9813 test loss: 7.5011196\n",
      "4640: ********* epoch 8 ********* test accuracy:0.9806 test loss: 7.490713\n",
      "4650: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.506691\n",
      "4660: ********* epoch 8 ********* test accuracy:0.9793 test loss: 7.55067\n",
      "4670: ********* epoch 8 ********* test accuracy:0.9792 test loss: 7.5251527\n",
      "4680: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.4539976\n",
      "4690: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.4655905\n",
      "4700: accuracy:0.98 loss: 4.159525 (lr:0.0003765705704250939)\n",
      "4700: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.3740325\n",
      "4710: ********* epoch 8 ********* test accuracy:0.98 test loss: 7.369071\n",
      "4720: ********* epoch 8 ********* test accuracy:0.9799 test loss: 7.3724337\n",
      "4730: ********* epoch 8 ********* test accuracy:0.9804 test loss: 7.3985686\n",
      "4740: ********* epoch 8 ********* test accuracy:0.9801 test loss: 7.4507\n",
      "4750: ********* epoch 8 ********* test accuracy:0.979 test loss: 7.4669867\n",
      "4760: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.322643\n",
      "4770: ********* epoch 8 ********* test accuracy:0.9797 test loss: 7.244497\n",
      "4780: ********* epoch 8 ********* test accuracy:0.9801 test loss: 7.200505\n",
      "4790: ********* epoch 8 ********* test accuracy:0.9804 test loss: 7.2754307\n",
      "4800: accuracy:1.0 loss: 0.56334955 (lr:0.0003630820645392963)\n",
      "4800: ********* epoch 9 ********* test accuracy:0.9806 test loss: 7.220021\n",
      "4810: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.1909533\n",
      "4820: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.226185\n",
      "4830: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.2859526\n",
      "4840: ********* epoch 9 ********* test accuracy:0.9795 test loss: 7.3639436\n",
      "4850: ********* epoch 9 ********* test accuracy:0.9793 test loss: 7.4049087\n",
      "4860: ********* epoch 9 ********* test accuracy:0.9795 test loss: 7.459895\n",
      "4870: ********* epoch 9 ********* test accuracy:0.9796 test loss: 7.5017734\n",
      "4880: ********* epoch 9 ********* test accuracy:0.9792 test loss: 7.5963774\n",
      "4890: ********* epoch 9 ********* test accuracy:0.9795 test loss: 7.547344\n",
      "4900: accuracy:1.0 loss: 1.0305631 (lr:0.00035025140084817447)\n",
      "4900: ********* epoch 9 ********* test accuracy:0.9802 test loss: 7.4767685\n",
      "4910: ********* epoch 9 ********* test accuracy:0.9806 test loss: 7.400796\n",
      "4920: ********* epoch 9 ********* test accuracy:0.9802 test loss: 7.355216\n",
      "4930: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.4462357\n",
      "4940: ********* epoch 9 ********* test accuracy:0.9798 test loss: 7.5252237\n",
      "4950: ********* epoch 9 ********* test accuracy:0.9792 test loss: 7.5561514\n",
      "4960: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.463386\n",
      "4970: ********* epoch 9 ********* test accuracy:0.9798 test loss: 7.3712497\n",
      "4980: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.3432026\n",
      "4990: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.272356\n",
      "5000: accuracy:0.99 loss: 2.1922612 (lr:0.00033804649600930654)\n",
      "5000: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.20242\n",
      "5010: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.22117\n",
      "5020: ********* epoch 9 ********* test accuracy:0.9806 test loss: 7.2138696\n",
      "5030: ********* epoch 9 ********* test accuracy:0.9802 test loss: 7.2622256\n",
      "5040: ********* epoch 9 ********* test accuracy:0.9803 test loss: 7.2452693\n",
      "5050: ********* epoch 9 ********* test accuracy:0.9806 test loss: 7.2525015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5060: ********* epoch 9 ********* test accuracy:0.9807 test loss: 7.2656326\n",
      "5070: ********* epoch 9 ********* test accuracy:0.9799 test loss: 7.2914867\n",
      "5080: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.3475947\n",
      "5090: ********* epoch 9 ********* test accuracy:0.9797 test loss: 7.4427085\n",
      "5100: accuracy:1.0 loss: 0.69449055 (lr:0.0003264368314033442)\n",
      "5100: ********* epoch 9 ********* test accuracy:0.9796 test loss: 7.397168\n",
      "5110: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.3175564\n",
      "5120: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.3120155\n",
      "5130: ********* epoch 9 ********* test accuracy:0.9802 test loss: 7.349185\n",
      "5140: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.385144\n",
      "5150: ********* epoch 9 ********* test accuracy:0.9804 test loss: 7.415215\n",
      "5160: ********* epoch 9 ********* test accuracy:0.9807 test loss: 7.3873615\n",
      "5170: ********* epoch 9 ********* test accuracy:0.9807 test loss: 7.3910475\n",
      "5180: ********* epoch 9 ********* test accuracy:0.9807 test loss: 7.4116716\n",
      "5190: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.4706306\n",
      "5200: accuracy:0.99 loss: 5.9386086 (lr:0.0003153933768215683)\n",
      "5200: ********* epoch 9 ********* test accuracy:0.9798 test loss: 7.50099\n",
      "5210: ********* epoch 9 ********* test accuracy:0.9797 test loss: 7.53728\n",
      "5220: ********* epoch 9 ********* test accuracy:0.9793 test loss: 7.5490713\n",
      "5230: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.5388894\n",
      "5240: ********* epoch 9 ********* test accuracy:0.9802 test loss: 7.4932466\n",
      "5250: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.4720645\n",
      "5260: ********* epoch 9 ********* test accuracy:0.9799 test loss: 7.525985\n",
      "5270: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.567689\n",
      "5280: ********* epoch 9 ********* test accuracy:0.9803 test loss: 7.581705\n",
      "5290: ********* epoch 9 ********* test accuracy:0.98 test loss: 7.5127983\n",
      "5300: accuracy:0.98 loss: 5.1244082 (lr:0.00030488851787524585)\n",
      "5300: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.4321074\n",
      "5310: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.30108\n",
      "5320: ********* epoch 9 ********* test accuracy:0.9809 test loss: 7.279425\n",
      "5330: ********* epoch 9 ********* test accuracy:0.9809 test loss: 7.2725663\n",
      "5340: ********* epoch 9 ********* test accuracy:0.9809 test loss: 7.2722754\n",
      "5350: ********* epoch 9 ********* test accuracy:0.981 test loss: 7.231047\n",
      "5360: ********* epoch 9 ********* test accuracy:0.9805 test loss: 7.176615\n",
      "5370: ********* epoch 9 ********* test accuracy:0.9808 test loss: 7.195181\n",
      "5380: ********* epoch 9 ********* test accuracy:0.9803 test loss: 7.2580175\n",
      "5390: ********* epoch 9 ********* test accuracy:0.9801 test loss: 7.3094974\n",
      "5400: accuracy:0.98 loss: 11.370219 (lr:0.0002948959869452743)\n",
      "5400: ********* epoch 10 ********* test accuracy:0.9807 test loss: 7.3674307\n",
      "5410: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.3418407\n",
      "5420: ********* epoch 10 ********* test accuracy:0.9806 test loss: 7.2858653\n",
      "5430: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.2696104\n",
      "5440: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.2506785\n",
      "5450: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.254983\n",
      "5460: ********* epoch 10 ********* test accuracy:0.9807 test loss: 7.302583\n",
      "5470: ********* epoch 10 ********* test accuracy:0.981 test loss: 7.2899513\n",
      "5480: ********* epoch 10 ********* test accuracy:0.9806 test loss: 7.2967396\n",
      "5490: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.3100576\n",
      "5500: accuracy:1.0 loss: 0.50311095 (lr:0.00028539079749945195)\n",
      "5500: ********* epoch 10 ********* test accuracy:0.9811 test loss: 7.352209\n",
      "5510: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.4048533\n",
      "5520: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.498741\n",
      "5530: ********* epoch 10 ********* test accuracy:0.9802 test loss: 7.490044\n",
      "5540: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.4621835\n",
      "5550: ********* epoch 10 ********* test accuracy:0.9807 test loss: 7.442317\n",
      "5560: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.5257263\n",
      "5570: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.582206\n",
      "5580: ********* epoch 10 ********* test accuracy:0.9808 test loss: 7.5823\n",
      "5590: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.549932\n",
      "5600: accuracy:1.0 loss: 0.5300179 (lr:0.00027634918161313215)\n",
      "5600: ********* epoch 10 ********* test accuracy:0.9812 test loss: 7.492102\n",
      "5610: ********* epoch 10 ********* test accuracy:0.9813 test loss: 7.4736347\n",
      "5620: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.383196\n",
      "5630: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.403511\n",
      "5640: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.3233604\n",
      "5650: ********* epoch 10 ********* test accuracy:0.9808 test loss: 7.368096\n",
      "5660: ********* epoch 10 ********* test accuracy:0.9799 test loss: 7.4685\n",
      "5670: ********* epoch 10 ********* test accuracy:0.9801 test loss: 7.443\n",
      "5680: ********* epoch 10 ********* test accuracy:0.9801 test loss: 7.4074073\n",
      "5690: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.397753\n",
      "5700: accuracy:1.0 loss: 0.32915205 (lr:0.0002677485305370315)\n",
      "5700: ********* epoch 10 ********* test accuracy:0.981 test loss: 7.3965416\n",
      "5710: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.4181333\n",
      "5720: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.511944\n",
      "5730: ********* epoch 10 ********* test accuracy:0.9808 test loss: 7.569688\n",
      "5740: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.6248364\n",
      "5750: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.672234\n",
      "5760: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.6824317\n",
      "5770: ********* epoch 10 ********* test accuracy:0.9804 test loss: 7.6419883\n",
      "5780: ********* epoch 10 ********* test accuracy:0.981 test loss: 7.64872\n",
      "5790: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.6165915\n",
      "5800: accuracy:1.0 loss: 0.24055085 (lr:0.000259567338163581)\n",
      "5800: ********* epoch 10 ********* test accuracy:0.981 test loss: 7.5494184\n",
      "5810: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.5239344\n",
      "5820: ********* epoch 10 ********* test accuracy:0.9813 test loss: 7.545136\n",
      "5830: ********* epoch 10 ********* test accuracy:0.9808 test loss: 7.407954\n",
      "5840: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.4006157\n",
      "5850: ********* epoch 10 ********* test accuracy:0.9802 test loss: 7.411014\n",
      "5860: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.4330873\n",
      "5870: ********* epoch 10 ********* test accuracy:0.9808 test loss: 7.4161477\n",
      "5880: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.4202166\n",
      "5890: ********* epoch 10 ********* test accuracy:0.9806 test loss: 7.4030457\n",
      "5900: accuracy:1.0 loss: 1.1280038 (lr:0.00025178514725045394)\n",
      "5900: ********* epoch 10 ********* test accuracy:0.9812 test loss: 7.395065\n",
      "5910: ********* epoch 10 ********* test accuracy:0.9809 test loss: 7.4199686\n",
      "5920: ********* epoch 10 ********* test accuracy:0.9806 test loss: 7.4299097\n",
      "5930: ********* epoch 10 ********* test accuracy:0.9805 test loss: 7.4818106\n",
      "5940: ********* epoch 10 ********* test accuracy:0.9807 test loss: 7.475829\n",
      "5950: ********* epoch 10 ********* test accuracy:0.9803 test loss: 7.3753076\n",
      "5960: ********* epoch 10 ********* test accuracy:0.9801 test loss: 7.3796244\n",
      "5970: ********* epoch 10 ********* test accuracy:0.9806 test loss: 7.3686795\n",
      "5980: ********* epoch 10 ********* test accuracy:0.9813 test loss: 7.387312\n",
      "5990: ********* epoch 10 ********* test accuracy:0.9812 test loss: 7.3897943\n",
      "6000: accuracy:1.0 loss: 0.074486434 (lr:0.00024438249826680544)\n",
      "6000: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.407067\n",
      "6010: ********* epoch 11 ********* test accuracy:0.9813 test loss: 7.402799\n",
      "6020: ********* epoch 11 ********* test accuracy:0.9813 test loss: 7.3829384\n",
      "6030: ********* epoch 11 ********* test accuracy:0.9815 test loss: 7.343401\n",
      "6040: ********* epoch 11 ********* test accuracy:0.9818 test loss: 7.2940454\n",
      "6050: ********* epoch 11 ********* test accuracy:0.9815 test loss: 7.325513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6060: ********* epoch 11 ********* test accuracy:0.9813 test loss: 7.3490834\n",
      "6070: ********* epoch 11 ********* test accuracy:0.9815 test loss: 7.366769\n",
      "6080: ********* epoch 11 ********* test accuracy:0.9813 test loss: 7.3599606\n",
      "6090: ********* epoch 11 ********* test accuracy:0.9815 test loss: 7.3559465\n",
      "6100: accuracy:1.0 loss: 0.52698934 (lr:0.00023734088073430873)\n",
      "6100: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.393638\n",
      "6110: ********* epoch 11 ********* test accuracy:0.9804 test loss: 7.4073563\n",
      "6120: ********* epoch 11 ********* test accuracy:0.9805 test loss: 7.401452\n",
      "6130: ********* epoch 11 ********* test accuracy:0.9801 test loss: 7.461903\n",
      "6140: ********* epoch 11 ********* test accuracy:0.98 test loss: 7.5028234\n",
      "6150: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.536073\n",
      "6160: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.51355\n",
      "6170: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.461508\n",
      "6180: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.4502015\n",
      "6190: ********* epoch 11 ********* test accuracy:0.9809 test loss: 7.433458\n",
      "6200: accuracy:0.99 loss: 1.1792359 (lr:0.00023064268694131766)\n",
      "6200: ********* epoch 11 ********* test accuracy:0.9807 test loss: 7.4307947\n",
      "6210: ********* epoch 11 ********* test accuracy:0.9802 test loss: 7.4083037\n",
      "6220: ********* epoch 11 ********* test accuracy:0.9804 test loss: 7.378237\n",
      "6230: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.3970823\n",
      "6240: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.4111156\n",
      "6250: ********* epoch 11 ********* test accuracy:0.9806 test loss: 7.3441744\n",
      "6260: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.3362\n",
      "6270: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.3236265\n",
      "6280: ********* epoch 11 ********* test accuracy:0.9812 test loss: 7.3249245\n",
      "6290: ********* epoch 11 ********* test accuracy:0.9807 test loss: 7.304756\n",
      "6300: accuracy:0.99 loss: 1.7724026 (lr:0.00022427116791441654)\n",
      "6300: ********* epoch 11 ********* test accuracy:0.9809 test loss: 7.3316054\n",
      "6310: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.3906193\n",
      "6320: ********* epoch 11 ********* test accuracy:0.9805 test loss: 7.442844\n",
      "6330: ********* epoch 11 ********* test accuracy:0.9806 test loss: 7.328341\n",
      "6340: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.353612\n",
      "6350: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.456463\n",
      "6360: ********* epoch 11 ********* test accuracy:0.9807 test loss: 7.4919014\n",
      "6370: ********* epoch 11 ********* test accuracy:0.9809 test loss: 7.424254\n",
      "6380: ********* epoch 11 ********* test accuracy:0.9807 test loss: 7.3809004\n",
      "6390: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.3310943\n",
      "6400: accuracy:1.0 loss: 0.26268 (lr:0.00021821039153726202)\n",
      "6400: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.289261\n",
      "6410: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.246599\n",
      "6420: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.229519\n",
      "6430: ********* epoch 11 ********* test accuracy:0.981 test loss: 7.2379284\n",
      "6440: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.284036\n",
      "6450: ********* epoch 11 ********* test accuracy:0.9806 test loss: 7.3085093\n",
      "6460: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.2636275\n",
      "6470: ********* epoch 11 ********* test accuracy:0.9812 test loss: 7.27657\n",
      "6480: ********* epoch 11 ********* test accuracy:0.9813 test loss: 7.3350573\n",
      "6490: ********* epoch 11 ********* test accuracy:0.9815 test loss: 7.3902555\n",
      "6500: accuracy:1.0 loss: 1.3613887 (lr:0.00021244520271199385)\n",
      "6500: ********* epoch 11 ********* test accuracy:0.9816 test loss: 7.401644\n",
      "6510: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.375797\n",
      "6520: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.2940626\n",
      "6530: ********* epoch 11 ********* test accuracy:0.9809 test loss: 7.229882\n",
      "6540: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.2055125\n",
      "6550: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.234873\n",
      "6560: ********* epoch 11 ********* test accuracy:0.9811 test loss: 7.2462463\n",
      "6570: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.190334\n",
      "6580: ********* epoch 11 ********* test accuracy:0.9808 test loss: 7.172577\n",
      "6590: ********* epoch 11 ********* test accuracy:0.9807 test loss: 7.1751466\n",
      "6600: accuracy:1.0 loss: 0.0805618 (lr:0.00020696118546359606)\n",
      "6600: ********* epoch 12 ********* test accuracy:0.981 test loss: 7.1639695\n",
      "6610: ********* epoch 12 ********* test accuracy:0.9806 test loss: 7.1821823\n",
      "6620: ********* epoch 12 ********* test accuracy:0.9801 test loss: 7.168953\n",
      "6630: ********* epoch 12 ********* test accuracy:0.9808 test loss: 7.155416\n",
      "6640: ********* epoch 12 ********* test accuracy:0.9802 test loss: 7.1879854\n",
      "6650: ********* epoch 12 ********* test accuracy:0.9802 test loss: 7.2351856\n",
      "6660: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.28318\n",
      "6670: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.3058925\n",
      "6680: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.316282\n",
      "6690: ********* epoch 12 ********* test accuracy:0.9802 test loss: 7.3085666\n",
      "6700: accuracy:0.98 loss: 4.9786663 (lr:0.0002017446268924506)\n",
      "6700: ********* epoch 12 ********* test accuracy:0.9804 test loss: 7.2563095\n",
      "6710: ********* epoch 12 ********* test accuracy:0.9805 test loss: 7.2297177\n",
      "6720: ********* epoch 12 ********* test accuracy:0.9806 test loss: 7.203588\n",
      "6730: ********* epoch 12 ********* test accuracy:0.9807 test loss: 7.2107353\n",
      "6740: ********* epoch 12 ********* test accuracy:0.9806 test loss: 7.2409263\n",
      "6750: ********* epoch 12 ********* test accuracy:0.9803 test loss: 7.2780805\n",
      "6760: ********* epoch 12 ********* test accuracy:0.9801 test loss: 7.3377514\n",
      "6770: ********* epoch 12 ********* test accuracy:0.9804 test loss: 7.3772855\n",
      "6780: ********* epoch 12 ********* test accuracy:0.9801 test loss: 7.3785386\n",
      "6790: ********* epoch 12 ********* test accuracy:0.9798 test loss: 7.438265\n",
      "6800: accuracy:0.98 loss: 7.559118 (lr:0.00019678248288494563)\n",
      "6800: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.455554\n",
      "6810: ********* epoch 12 ********* test accuracy:0.9798 test loss: 7.4429827\n",
      "6820: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.3712325\n",
      "6830: ********* epoch 12 ********* test accuracy:0.9802 test loss: 7.3564625\n",
      "6840: ********* epoch 12 ********* test accuracy:0.9805 test loss: 7.3536596\n",
      "6850: ********* epoch 12 ********* test accuracy:0.9807 test loss: 7.3373213\n",
      "6860: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.32909\n",
      "6870: ********* epoch 12 ********* test accuracy:0.9814 test loss: 7.3581705\n",
      "6880: ********* epoch 12 ********* test accuracy:0.9812 test loss: 7.339933\n",
      "6890: ********* epoch 12 ********* test accuracy:0.9812 test loss: 7.308668\n",
      "6900: accuracy:0.99 loss: 1.5429469 (lr:0.00019206234549639704)\n",
      "6900: ********* epoch 12 ********* test accuracy:0.9814 test loss: 7.2777486\n",
      "6910: ********* epoch 12 ********* test accuracy:0.9813 test loss: 7.293845\n",
      "6920: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.3540673\n",
      "6930: ********* epoch 12 ********* test accuracy:0.981 test loss: 7.368905\n",
      "6940: ********* epoch 12 ********* test accuracy:0.9816 test loss: 7.3776445\n",
      "6950: ********* epoch 12 ********* test accuracy:0.9812 test loss: 7.328559\n",
      "6960: ********* epoch 12 ********* test accuracy:0.9814 test loss: 7.3075757\n",
      "6970: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.2975173\n",
      "6980: ********* epoch 12 ********* test accuracy:0.9815 test loss: 7.2968826\n",
      "6990: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.2897143\n",
      "7000: accuracy:0.99 loss: 2.9646478 (lr:0.00018757241192472366)\n",
      "7000: ********* epoch 12 ********* test accuracy:0.9812 test loss: 7.286236\n",
      "7010: ********* epoch 12 ********* test accuracy:0.9815 test loss: 7.313985\n",
      "7020: ********* epoch 12 ********* test accuracy:0.9813 test loss: 7.366399\n",
      "7030: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.419271\n",
      "7040: ********* epoch 12 ********* test accuracy:0.9815 test loss: 7.404814\n",
      "7050: ********* epoch 12 ********* test accuracy:0.981 test loss: 7.4133835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7060: ********* epoch 12 ********* test accuracy:0.9812 test loss: 7.4284186\n",
      "7070: ********* epoch 12 ********* test accuracy:0.9809 test loss: 7.458964\n",
      "7080: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.486237\n",
      "7090: ********* epoch 12 ********* test accuracy:0.9811 test loss: 7.4967966\n",
      "7100: accuracy:1.0 loss: 0.8488221 (lr:0.00018330145499729437)\n",
      "7100: ********* epoch 12 ********* test accuracy:0.9809 test loss: 7.5164466\n",
      "7110: ********* epoch 12 ********* test accuracy:0.981 test loss: 7.537671\n",
      "7120: ********* epoch 12 ********* test accuracy:0.9809 test loss: 7.536288\n",
      "7130: ********* epoch 12 ********* test accuracy:0.9807 test loss: 7.5473404\n",
      "7140: ********* epoch 12 ********* test accuracy:0.9804 test loss: 7.5275817\n",
      "7150: ********* epoch 12 ********* test accuracy:0.9804 test loss: 7.5037813\n",
      "7160: ********* epoch 12 ********* test accuracy:0.9802 test loss: 7.5652337\n",
      "7170: ********* epoch 12 ********* test accuracy:0.98 test loss: 7.591196\n",
      "7180: ********* epoch 12 ********* test accuracy:0.9804 test loss: 7.542043\n",
      "7190: ********* epoch 12 ********* test accuracy:0.9807 test loss: 7.4578705\n",
      "7200: accuracy:0.99 loss: 8.253965 (lr:0.00017923879509714843)\n",
      "7200: ********* epoch 13 ********* test accuracy:0.9804 test loss: 7.48488\n",
      "7210: ********* epoch 13 ********* test accuracy:0.9805 test loss: 7.487925\n",
      "7220: ********* epoch 13 ********* test accuracy:0.9808 test loss: 7.46687\n",
      "7230: ********* epoch 13 ********* test accuracy:0.9811 test loss: 7.4547586\n",
      "7240: ********* epoch 13 ********* test accuracy:0.9813 test loss: 7.456479\n",
      "7250: ********* epoch 13 ********* test accuracy:0.9816 test loss: 7.420092\n",
      "7260: ********* epoch 13 ********* test accuracy:0.9808 test loss: 7.378117\n",
      "7270: ********* epoch 13 ********* test accuracy:0.9811 test loss: 7.3828588\n",
      "7280: ********* epoch 13 ********* test accuracy:0.9814 test loss: 7.391461\n",
      "7290: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.35621\n",
      "7300: accuracy:0.98 loss: 7.185038 (lr:0.0001753742734583905)\n",
      "7300: ********* epoch 13 ********* test accuracy:0.9814 test loss: 7.298591\n",
      "7310: ********* epoch 13 ********* test accuracy:0.9815 test loss: 7.2918835\n",
      "7320: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.246208\n",
      "7330: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.2246065\n",
      "7340: ********* epoch 13 ********* test accuracy:0.9807 test loss: 7.22623\n",
      "7350: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.227069\n",
      "7360: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.2612605\n",
      "7370: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.333722\n",
      "7380: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.3677115\n",
      "7390: ********* epoch 13 ********* test accuracy:0.981 test loss: 7.357155\n",
      "7400: accuracy:1.0 loss: 0.13477184 (lr:0.00017169822676398424)\n",
      "7400: ********* epoch 13 ********* test accuracy:0.981 test loss: 7.3603654\n",
      "7410: ********* epoch 13 ********* test accuracy:0.9807 test loss: 7.325158\n",
      "7420: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.33938\n",
      "7430: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.367167\n",
      "7440: ********* epoch 13 ********* test accuracy:0.9815 test loss: 7.40862\n",
      "7450: ********* epoch 13 ********* test accuracy:0.9813 test loss: 7.4522176\n",
      "7460: ********* epoch 13 ********* test accuracy:0.9815 test loss: 7.483374\n",
      "7470: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.489861\n",
      "7480: ********* epoch 13 ********* test accuracy:0.9807 test loss: 7.4857078\n",
      "7490: ********* epoch 13 ********* test accuracy:0.9801 test loss: 7.460034\n",
      "7500: accuracy:0.99 loss: 3.7922435 (lr:0.00016820146298242642)\n",
      "7500: ********* epoch 13 ********* test accuracy:0.9801 test loss: 7.417966\n",
      "7510: ********* epoch 13 ********* test accuracy:0.9805 test loss: 7.3781824\n",
      "7520: ********* epoch 13 ********* test accuracy:0.9813 test loss: 7.340609\n",
      "7530: ********* epoch 13 ********* test accuracy:0.9816 test loss: 7.356273\n",
      "7540: ********* epoch 13 ********* test accuracy:0.9815 test loss: 7.4104466\n",
      "7550: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.4022746\n",
      "7560: ********* epoch 13 ********* test accuracy:0.9808 test loss: 7.3335595\n",
      "7570: ********* epoch 13 ********* test accuracy:0.9804 test loss: 7.321471\n",
      "7580: ********* epoch 13 ********* test accuracy:0.9802 test loss: 7.3712206\n",
      "7590: ********* epoch 13 ********* test accuracy:0.9803 test loss: 7.378344\n",
      "7600: accuracy:1.0 loss: 0.9909275 (lr:0.00016487523838288026)\n",
      "7600: ********* epoch 13 ********* test accuracy:0.98 test loss: 7.3562717\n",
      "7610: ********* epoch 13 ********* test accuracy:0.9799 test loss: 7.3954\n",
      "7620: ********* epoch 13 ********* test accuracy:0.9801 test loss: 7.429967\n",
      "7630: ********* epoch 13 ********* test accuracy:0.9801 test loss: 7.471421\n",
      "7640: ********* epoch 13 ********* test accuracy:0.9807 test loss: 7.4460754\n",
      "7650: ********* epoch 13 ********* test accuracy:0.9806 test loss: 7.434086\n",
      "7660: ********* epoch 13 ********* test accuracy:0.9807 test loss: 7.432939\n",
      "7670: ********* epoch 13 ********* test accuracy:0.9806 test loss: 7.4225097\n",
      "7680: ********* epoch 13 ********* test accuracy:0.9805 test loss: 7.4153104\n",
      "7690: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.3885045\n",
      "7700: accuracy:1.0 loss: 0.8457242 (lr:0.0001617112356712938)\n",
      "7700: ********* epoch 13 ********* test accuracy:0.9808 test loss: 7.3334365\n",
      "7710: ********* epoch 13 ********* test accuracy:0.9812 test loss: 7.3094954\n",
      "7720: ********* epoch 13 ********* test accuracy:0.981 test loss: 7.2989407\n",
      "7730: ********* epoch 13 ********* test accuracy:0.9814 test loss: 7.303113\n",
      "7740: ********* epoch 13 ********* test accuracy:0.9814 test loss: 7.3472977\n",
      "7750: ********* epoch 13 ********* test accuracy:0.9809 test loss: 7.379397\n",
      "7760: ********* epoch 13 ********* test accuracy:0.9808 test loss: 7.397338\n",
      "7770: ********* epoch 13 ********* test accuracy:0.9805 test loss: 7.481363\n",
      "7780: ********* epoch 13 ********* test accuracy:0.98 test loss: 7.5500994\n",
      "7790: ********* epoch 13 ********* test accuracy:0.9796 test loss: 7.568597\n",
      "7800: accuracy:0.99 loss: 1.3294756 (lr:0.00015870154319283275)\n",
      "7800: ********* epoch 14 ********* test accuracy:0.9797 test loss: 7.5939016\n",
      "7810: ********* epoch 14 ********* test accuracy:0.98 test loss: 7.559634\n",
      "7820: ********* epoch 14 ********* test accuracy:0.98 test loss: 7.5042067\n",
      "7830: ********* epoch 14 ********* test accuracy:0.9802 test loss: 7.476703\n",
      "7840: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.4318604\n",
      "7850: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.439574\n",
      "7860: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.4552097\n",
      "7870: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.445069\n",
      "7880: ********* epoch 14 ********* test accuracy:0.9811 test loss: 7.4639096\n",
      "7890: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.484228\n",
      "7900: accuracy:1.0 loss: 0.8503359 (lr:0.00015583863514862209)\n",
      "7900: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.4896684\n",
      "7910: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.4730964\n",
      "7920: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.472666\n",
      "7930: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.482542\n",
      "7940: ********* epoch 14 ********* test accuracy:0.9805 test loss: 7.4973373\n",
      "7950: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.506104\n",
      "7960: ********* epoch 14 ********* test accuracy:0.9802 test loss: 7.5039806\n",
      "7970: ********* epoch 14 ********* test accuracy:0.9804 test loss: 7.5080724\n",
      "7980: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.5231442\n",
      "7990: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.5246534\n",
      "8000: accuracy:1.0 loss: 0.7917777 (lr:0.00015311535277732913)\n",
      "8000: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.517735\n",
      "8010: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.501358\n",
      "8020: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.5110803\n",
      "8030: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.504177\n",
      "8040: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.5533814\n",
      "8050: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.574728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8060: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.5701\n",
      "8070: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.5676837\n",
      "8080: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.561821\n",
      "8090: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.605814\n",
      "8100: accuracy:0.97 loss: 8.366529 (lr:0.0001505248864545312)\n",
      "8100: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.5958805\n",
      "8110: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.5554347\n",
      "8120: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.502295\n",
      "8130: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.436462\n",
      "8140: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.4317174\n",
      "8150: ********* epoch 14 ********* test accuracy:0.9801 test loss: 7.4304214\n",
      "8160: ********* epoch 14 ********* test accuracy:0.9802 test loss: 7.4049435\n",
      "8170: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.3937693\n",
      "8180: ********* epoch 14 ********* test accuracy:0.9804 test loss: 7.4206204\n",
      "8190: ********* epoch 14 ********* test accuracy:0.9808 test loss: 7.4347863\n",
      "8200: accuracy:0.99 loss: 3.5475378 (lr:0.00014806075866510764)\n",
      "8200: ********* epoch 14 ********* test accuracy:0.9805 test loss: 7.4685783\n",
      "8210: ********* epoch 14 ********* test accuracy:0.9805 test loss: 7.5023875\n",
      "8220: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.517285\n",
      "8230: ********* epoch 14 ********* test accuracy:0.9809 test loss: 7.5045466\n",
      "8240: ********* epoch 14 ********* test accuracy:0.9809 test loss: 7.4452443\n",
      "8250: ********* epoch 14 ********* test accuracy:0.9813 test loss: 7.425222\n",
      "8260: ********* epoch 14 ********* test accuracy:0.9807 test loss: 7.420017\n",
      "8270: ********* epoch 14 ********* test accuracy:0.9806 test loss: 7.396946\n",
      "8280: ********* epoch 14 ********* test accuracy:0.9809 test loss: 7.3682785\n",
      "8290: ********* epoch 14 ********* test accuracy:0.9814 test loss: 7.342992\n",
      "8300: accuracy:1.0 loss: 0.2204523 (lr:0.00014571680780607802)\n",
      "8300: ********* epoch 14 ********* test accuracy:0.9814 test loss: 7.3322587\n",
      "8310: ********* epoch 14 ********* test accuracy:0.9813 test loss: 7.331997\n",
      "8320: ********* epoch 14 ********* test accuracy:0.9814 test loss: 7.343753\n",
      "8330: ********* epoch 14 ********* test accuracy:0.9811 test loss: 7.361604\n",
      "8340: ********* epoch 14 ********* test accuracy:0.9814 test loss: 7.3441133\n",
      "8350: ********* epoch 14 ********* test accuracy:0.9817 test loss: 7.343949\n",
      "8360: ********* epoch 14 ********* test accuracy:0.9814 test loss: 7.362162\n",
      "8370: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.401321\n",
      "8380: ********* epoch 14 ********* test accuracy:0.981 test loss: 7.4069166\n",
      "8390: ********* epoch 14 ********* test accuracy:0.9809 test loss: 7.417235\n",
      "8400: accuracy:1.0 loss: 0.08018461 (lr:0.00014348717277938534)\n",
      "8400: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.4322314\n",
      "8410: ********* epoch 15 ********* test accuracy:0.9812 test loss: 7.4570513\n",
      "8420: ********* epoch 15 ********* test accuracy:0.9813 test loss: 7.444329\n",
      "8430: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.427536\n",
      "8440: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.452941\n",
      "8450: ********* epoch 15 ********* test accuracy:0.9813 test loss: 7.454636\n",
      "8460: ********* epoch 15 ********* test accuracy:0.9815 test loss: 7.460561\n",
      "8470: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.470881\n",
      "8480: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.494643\n",
      "8490: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.51521\n",
      "8500: accuracy:1.0 loss: 0.649209 (lr:0.00014136627833609785)\n",
      "8500: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.5564904\n",
      "8510: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.587662\n",
      "8520: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.618803\n",
      "8530: ********* epoch 15 ********* test accuracy:0.9807 test loss: 7.610269\n",
      "8540: ********* epoch 15 ********* test accuracy:0.9803 test loss: 7.608936\n",
      "8550: ********* epoch 15 ********* test accuracy:0.9804 test loss: 7.606697\n",
      "8560: ********* epoch 15 ********* test accuracy:0.9804 test loss: 7.5625577\n",
      "8570: ********* epoch 15 ********* test accuracy:0.9807 test loss: 7.522335\n",
      "8580: ********* epoch 15 ********* test accuracy:0.9807 test loss: 7.4887404\n",
      "8590: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.4842205\n",
      "8600: accuracy:0.99 loss: 1.5217068 (lr:0.00013934882113538272)\n",
      "8600: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.539672\n",
      "8610: ********* epoch 15 ********* test accuracy:0.9813 test loss: 7.603746\n",
      "8620: ********* epoch 15 ********* test accuracy:0.9815 test loss: 7.627911\n",
      "8630: ********* epoch 15 ********* test accuracy:0.9815 test loss: 7.6464167\n",
      "8640: ********* epoch 15 ********* test accuracy:0.9815 test loss: 7.656548\n",
      "8650: ********* epoch 15 ********* test accuracy:0.9813 test loss: 7.6214256\n",
      "8660: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.5835323\n",
      "8670: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.556477\n",
      "8680: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.509188\n",
      "8690: ********* epoch 15 ********* test accuracy:0.9813 test loss: 7.469679\n",
      "8700: accuracy:1.0 loss: 1.38884 (lr:0.00013742975648339164)\n",
      "8700: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.46328\n",
      "8710: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.442902\n",
      "8720: ********* epoch 15 ********* test accuracy:0.9812 test loss: 7.445653\n",
      "8730: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.4671416\n",
      "8740: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.4373136\n",
      "8750: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.379327\n",
      "8760: ********* epoch 15 ********* test accuracy:0.9806 test loss: 7.3284426\n",
      "8770: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.2972007\n",
      "8780: ********* epoch 15 ********* test accuracy:0.9812 test loss: 7.288612\n",
      "8790: ********* epoch 15 ********* test accuracy:0.9812 test loss: 7.2913027\n",
      "8800: accuracy:1.0 loss: 0.061700724 (lr:0.00013560428571889846)\n",
      "8800: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.320415\n",
      "8810: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.362029\n",
      "8820: ********* epoch 15 ********* test accuracy:0.9806 test loss: 7.421454\n",
      "8830: ********* epoch 15 ********* test accuracy:0.9806 test loss: 7.44989\n",
      "8840: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.478359\n",
      "8850: ********* epoch 15 ********* test accuracy:0.9807 test loss: 7.47625\n",
      "8860: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.45385\n",
      "8870: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.458182\n",
      "8880: ********* epoch 15 ********* test accuracy:0.981 test loss: 7.476665\n",
      "8890: ********* epoch 15 ********* test accuracy:0.9811 test loss: 7.5261736\n",
      "8900: accuracy:1.0 loss: 0.74756706 (lr:0.0001338678442141468)\n",
      "8900: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.5349913\n",
      "8910: ********* epoch 15 ********* test accuracy:0.9806 test loss: 7.530076\n",
      "8920: ********* epoch 15 ********* test accuracy:0.9805 test loss: 7.525721\n",
      "8930: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.5326867\n",
      "8940: ********* epoch 15 ********* test accuracy:0.9809 test loss: 7.5154\n",
      "8950: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.4738183\n",
      "8960: ********* epoch 15 ********* test accuracy:0.9806 test loss: 7.43216\n",
      "8970: ********* epoch 15 ********* test accuracy:0.9804 test loss: 7.433547\n",
      "8980: ********* epoch 15 ********* test accuracy:0.9808 test loss: 7.388068\n",
      "8990: ********* epoch 15 ********* test accuracy:0.9805 test loss: 7.3723035\n",
      "9000: accuracy:1.0 loss: 0.29466975 (lr:0.0001322160899609027)\n",
      "9000: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.3715796\n",
      "9010: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.3590426\n",
      "9020: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.368823\n",
      "9030: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.3860526\n",
      "9040: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.416892\n",
      "9050: ********* epoch 16 ********* test accuracy:0.9814 test loss: 7.413513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9060: ********* epoch 16 ********* test accuracy:0.9814 test loss: 7.429572\n",
      "9070: ********* epoch 16 ********* test accuracy:0.9814 test loss: 7.450171\n",
      "9080: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.4545555\n",
      "9090: ********* epoch 16 ********* test accuracy:0.9808 test loss: 7.42843\n",
      "9100: accuracy:0.99 loss: 3.7452064 (lr:0.00013064489271317272)\n",
      "9100: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.4107714\n",
      "9110: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.3863893\n",
      "9120: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.3668613\n",
      "9130: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.3737645\n",
      "9140: ********* epoch 16 ********* test accuracy:0.9814 test loss: 7.365735\n",
      "9150: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.371043\n",
      "9160: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.381619\n",
      "9170: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.3938556\n",
      "9180: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.398148\n",
      "9190: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.4189873\n",
      "9200: accuracy:0.99 loss: 3.1253033 (lr:0.0001291503236594374)\n",
      "9200: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.403579\n",
      "9210: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.372716\n",
      "9220: ********* epoch 16 ********* test accuracy:0.9815 test loss: 7.3454714\n",
      "9230: ********* epoch 16 ********* test accuracy:0.9816 test loss: 7.314179\n",
      "9240: ********* epoch 16 ********* test accuracy:0.9818 test loss: 7.2985144\n",
      "9250: ********* epoch 16 ********* test accuracy:0.9819 test loss: 7.3005185\n",
      "9260: ********* epoch 16 ********* test accuracy:0.9818 test loss: 7.314511\n",
      "9270: ********* epoch 16 ********* test accuracy:0.9817 test loss: 7.3242373\n",
      "9280: ********* epoch 16 ********* test accuracy:0.9817 test loss: 7.3263736\n",
      "9290: ********* epoch 16 ********* test accuracy:0.9818 test loss: 7.3387437\n",
      "9300: accuracy:1.0 loss: 0.40153557 (lr:0.00012772864559857617)\n",
      "9300: ********* epoch 16 ********* test accuracy:0.9815 test loss: 7.3486986\n",
      "9310: ********* epoch 16 ********* test accuracy:0.9808 test loss: 7.354902\n",
      "9320: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.367163\n",
      "9330: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.3944993\n",
      "9340: ********* epoch 16 ********* test accuracy:0.9808 test loss: 7.41492\n",
      "9350: ********* epoch 16 ********* test accuracy:0.981 test loss: 7.4032693\n",
      "9360: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.405486\n",
      "9370: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.400798\n",
      "9380: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.4139605\n",
      "9390: ********* epoch 16 ********* test accuracy:0.981 test loss: 7.41581\n",
      "9400: accuracy:1.0 loss: 0.07152699 (lr:0.00012637630359491788)\n",
      "9400: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.3940954\n",
      "9410: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.38825\n",
      "9420: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.3778257\n",
      "9430: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.3768826\n",
      "9440: ********* epoch 16 ********* test accuracy:0.9815 test loss: 7.393461\n",
      "9450: ********* epoch 16 ********* test accuracy:0.9819 test loss: 7.385764\n",
      "9460: ********* epoch 16 ********* test accuracy:0.9816 test loss: 7.3960266\n",
      "9470: ********* epoch 16 ********* test accuracy:0.9818 test loss: 7.414207\n",
      "9480: ********* epoch 16 ********* test accuracy:0.9815 test loss: 7.405112\n",
      "9490: ********* epoch 16 ********* test accuracy:0.9811 test loss: 7.3936567\n",
      "9500: accuracy:0.99 loss: 2.2109673 (lr:0.00012508991608904985)\n",
      "9500: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.386638\n",
      "9510: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.3850436\n",
      "9520: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.3906193\n",
      "9530: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.3667965\n",
      "9540: ********* epoch 16 ********* test accuracy:0.9807 test loss: 7.388994\n",
      "9550: ********* epoch 16 ********* test accuracy:0.9806 test loss: 7.40121\n",
      "9560: ********* epoch 16 ********* test accuracy:0.9809 test loss: 7.4147425\n",
      "9570: ********* epoch 16 ********* test accuracy:0.9812 test loss: 7.4235134\n",
      "9580: ********* epoch 16 ********* test accuracy:0.9813 test loss: 7.427152\n",
      "9590: ********* epoch 16 ********* test accuracy:0.9814 test loss: 7.4468265\n",
      "9600: accuracy:0.99 loss: 3.7700586 (lr:0.0001238662664421581)\n",
      "9600: ********* epoch 17 ********* test accuracy:0.9814 test loss: 7.4271173\n",
      "9610: ********* epoch 17 ********* test accuracy:0.9812 test loss: 7.4109993\n",
      "9620: ********* epoch 17 ********* test accuracy:0.9815 test loss: 7.4245634\n",
      "9630: ********* epoch 17 ********* test accuracy:0.9815 test loss: 7.41088\n",
      "9640: ********* epoch 17 ********* test accuracy:0.9817 test loss: 7.4109287\n",
      "9650: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.4324713\n",
      "9660: ********* epoch 17 ********* test accuracy:0.9814 test loss: 7.435154\n",
      "9670: ********* epoch 17 ********* test accuracy:0.9816 test loss: 7.430791\n",
      "9680: ********* epoch 17 ********* test accuracy:0.9816 test loss: 7.43884\n",
      "9690: ********* epoch 17 ********* test accuracy:0.9815 test loss: 7.4543943\n",
      "9700: accuracy:0.99 loss: 3.3130786 (lr:0.00012270229489275475)\n",
      "9700: ********* epoch 17 ********* test accuracy:0.9816 test loss: 7.461512\n",
      "9710: ********* epoch 17 ********* test accuracy:0.9812 test loss: 7.483872\n",
      "9720: ********* epoch 17 ********* test accuracy:0.9814 test loss: 7.4867554\n",
      "9730: ********* epoch 17 ********* test accuracy:0.9812 test loss: 7.492058\n",
      "9740: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.5012126\n",
      "9750: ********* epoch 17 ********* test accuracy:0.9809 test loss: 7.5235314\n",
      "9760: ********* epoch 17 ********* test accuracy:0.9811 test loss: 7.5123916\n",
      "9770: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.499344\n",
      "9780: ********* epoch 17 ********* test accuracy:0.9813 test loss: 7.5146646\n",
      "9790: ********* epoch 17 ********* test accuracy:0.9813 test loss: 7.5486207\n",
      "9800: accuracy:1.0 loss: 0.506691 (lr:0.00012159509090568058)\n",
      "9800: ********* epoch 17 ********* test accuracy:0.9811 test loss: 7.5480657\n",
      "9810: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.5597706\n",
      "9820: ********* epoch 17 ********* test accuracy:0.9811 test loss: 7.5712657\n",
      "9830: ********* epoch 17 ********* test accuracy:0.9811 test loss: 7.605023\n",
      "9840: ********* epoch 17 ********* test accuracy:0.9809 test loss: 7.613209\n",
      "9850: ********* epoch 17 ********* test accuracy:0.9807 test loss: 7.6658683\n",
      "9860: ********* epoch 17 ********* test accuracy:0.9805 test loss: 7.7232895\n",
      "9870: ********* epoch 17 ********* test accuracy:0.9805 test loss: 7.7327466\n",
      "9880: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.7322187\n",
      "9890: ********* epoch 17 ********* test accuracy:0.981 test loss: 7.7479086\n",
      "9900: accuracy:0.99 loss: 1.6779029 (lr:0.00012054188589425116)\n",
      "9900: ********* epoch 17 ********* test accuracy:0.9809 test loss: 7.7525206\n",
      "9910: ********* epoch 17 ********* test accuracy:0.9806 test loss: 7.740703\n",
      "9920: ********* epoch 17 ********* test accuracy:0.9808 test loss: 7.7040935\n",
      "9930: ********* epoch 17 ********* test accuracy:0.9805 test loss: 7.7123003\n",
      "9940: ********* epoch 17 ********* test accuracy:0.9806 test loss: 7.7429442\n",
      "9950: ********* epoch 17 ********* test accuracy:0.9807 test loss: 7.706095\n",
      "9960: ********* epoch 17 ********* test accuracy:0.9804 test loss: 7.669768\n",
      "9970: ********* epoch 17 ********* test accuracy:0.9809 test loss: 7.610964\n",
      "9980: ********* epoch 17 ********* test accuracy:0.9807 test loss: 7.5189614\n",
      "9990: ********* epoch 17 ********* test accuracy:0.9807 test loss: 7.4866624\n",
      "10000: accuracy:0.99 loss: 2.3340452 (lr:0.00011954004629734786)\n",
      "10000: ********* epoch 17 ********* test accuracy:0.9809 test loss: 7.4969144\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000+1): training_step(i, i % 10 == 0, i % 100 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
