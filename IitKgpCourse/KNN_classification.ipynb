{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fe518c6c-0e88-3d55-136a-125ee051d769",
    "_uuid": "e780923fd41b70bf75443ee466b7129557ff8284"
   },
   "source": [
    "## Let's walk through a k-Nearest Neighbors Classifier and find the best value for k.  \n",
    "\n",
    "## In this kaggle notebook, I'm testing my ability to run a knn classifier on a new data set.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "491074e7-9126-64c5-8730-b7d1255c3b70",
    "_execution_state": "idle",
    "_uuid": "e063484ae2fd4dabc551f8704d174c7b01f94534"
   },
   "outputs": [],
   "source": [
    "# import some libraries.  I don't think we'll need all these, but it doesn't hurt to have them ready. \n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import sys\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5e17b6f-d24c-acf1-5e70-83582b31445d",
    "_execution_state": "idle",
    "_uuid": "39c8331f6e7ddfbc8e0de669cb0627b27958df97"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "387930e2-3f90-a8cf-fb91-87ffed66a26d",
    "_execution_state": "idle",
    "_uuid": "72eb9697b96e6466b153d874a17c4a7573981c17"
   },
   "outputs": [],
   "source": [
    "# look at the keys\n",
    "print(digits.keys())\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7246d45-4727-3a71-c1c6-0f31be0c1fd6",
    "_execution_state": "idle",
    "_uuid": "cf2cb86bc572a4e6b8e5885fb93e21820577d787"
   },
   "outputs": [],
   "source": [
    "# Print the shape of the images and data keys\n",
    "print(digits.images.shape)\n",
    "print(digits.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02e3fd57-7447-12f2-1a5f-0fa2124a49dd",
    "_execution_state": "idle",
    "_uuid": "e233c62608f1a0c33bf29a9b00a550d83aea582d"
   },
   "outputs": [],
   "source": [
    "# Display digit 1010\n",
    "plt.imshow(digits.images[1010], cmap=plt.cm.gray_r, interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eaecf729-152d-a543-50bf-0b4e9925b118",
    "_execution_state": "idle",
    "_uuid": "151681ff28ff945641c6fd7995e1547609e4b6cc"
   },
   "outputs": [],
   "source": [
    "# Create feature and target arrays\n",
    "X = digits.data\n",
    "y = digits.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de019cbf-25da-7eb4-0857-9279bf0766d6",
    "_uuid": "0386e01e294a852c9f648ff167ee2995aa9df2c2"
   },
   "source": [
    "### Let's split the data into testing and training sets.  Kaggle already does the splitting for us, but it is good to know how to do this on our own in the real world.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6f786508-c6c6-13bc-fbe7-e7935df81688",
    "_execution_state": "idle",
    "_uuid": "c7e27366366485e20e8928215d4cfcb56953ca70"
   },
   "outputs": [],
   "source": [
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be7bace8-79db-1349-62f2-8fb933b7a274",
    "_uuid": "6e1968dad2e054f3bb9c1d1ca1044caf3a3966a4"
   },
   "source": [
    "### Fit the Knn classifier with 7 neighbors.  You can chose another number here.  \n",
    "\n",
    "### We'll go through some steps below to determine which number might work best for this data.  For now we will use 7 to see what happens.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b2660ec-f7d7-4009-a6f2-c90273d7f8e8",
    "_execution_state": "idle",
    "_uuid": "7d5a2294cb51f834050a1be9179c26a66066f61e"
   },
   "outputs": [],
   "source": [
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1812f78e-13b7-f366-8d3e-c4fbaea53619",
    "_execution_state": "idle",
    "_uuid": "bba4dbd8faf319b57665189420dcd504a61743e4"
   },
   "outputs": [],
   "source": [
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4350df2f-b9a7-bd8b-79d4-4266eb5f1b4d",
    "_execution_state": "idle",
    "_uuid": "64a84b293a8a099dcf7249574edf53045463eb6d"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "147017ab-0e57-8c0e-912b-23cfd1e37962",
    "_uuid": "130e440d09cdc2ccf7140e8ee5d63b03efc37186"
   },
   "source": [
    "### Not bad! 98 percent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c1c48ab-06dc-a8ab-9112-9b651a4e4ca4",
    "_execution_state": "idle",
    "_uuid": "d4a4930611afaf78ee5149dd38f9d9bbc2f9e224"
   },
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3222705a-68f2-6429-015d-d412785ae5c3",
    "_uuid": "12596bd915cf36ac0af79b0a413b8dc537d023f2"
   },
   "source": [
    "## Finding a good k value\n",
    "\n",
    "### Let's now compute and plot the training and testing accuracy scores for a variety of different neighbor values. By observing how the accuracy scores differ for the training and testing sets with different values of k, you can develop an intuition for overfitting and underfitting a model.\n",
    "\n",
    "#### Let's now streamline some of the steps we did above into a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6db91f3f-c1e1-4f9c-ed2e-2fff5cc35ebc",
    "_execution_state": "idle",
    "_uuid": "135aad8eeed648dc6796595971d4b0dde9d88991"
   },
   "outputs": [],
   "source": [
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "91c2ad8e-9166-b47b-d9df-61bd2f1b49eb",
    "_execution_state": "idle",
    "_uuid": "be999a070073101119201653a5ac62846e4160e3"
   },
   "outputs": [],
   "source": [
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f5beec9-30fc-031e-42ce-853b1eb413d9",
    "_uuid": "6c4038dfe2313d59b24c9a6a488be1ab1d537850"
   },
   "source": [
    "As we can see from the plot, it appears like the test accuracy is highest when using 3 and 5 neighbors.  7 isn't too bad, but using 8 neighbors or more seems to result in a simple model that under fits the data. "
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
